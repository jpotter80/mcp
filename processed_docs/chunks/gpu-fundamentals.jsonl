{"chunk_id": "gpu-fundamentals-000", "document_id": "gpu-fundamentals", "content": "This guide explores the fundamentals of GPU programming using the Mojo\nprogramming language, covering essential concepts and techniques for developing\nGPU-accelerated applications that can work on a variety of supported GPUs from\ndifferent vendors.\n\nKey topics covered in this guide:\n\n- Understanding the CPU-GPU programming model.\n- Working with Mojo's GPU support through the Standard Library.\n- Managing GPU devices and contexts using `DeviceContext`.\n- Writing and executing kernel functions for parallel computation.\n- Memory management and data transfer between CPU and GPU.\n- Organizing threads and thread blocks for optimal performance.\n\nBefore diving into GPU programming, ensure you have a [compatible\nGPU](/max/faq#gpu-requirements) and the necessary development environment\ninstalled. And if you're new to GPU programming, we suggest you read the\n[Intro to GPU architectures](/mojo/manual/gpu/architecture).", "position": 0, "token_count": 192, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-000", "document_id": "gpu-fundamentals", "position": 0, "token_count": 192, "has_code": false, "overlap_with_previous": false, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-001", "document_id": "gpu-fundamentals", "content": "## Overview of GPU Programming in Mojo\n\nThe Mojo language, including its Standard Library and open source MAX kernels\nlibrary, allow you to develop GPU-enabled applications. See the [What are the\nGPU requirements?](/max/faq#gpu-requirements) section of the documentation for a\nlist of currently supported GPUs and additional software requirements.", "position": 1, "token_count": 77, "has_code": false, "section_hierarchy": ["Overview of GPU Programming in Mojo"], "metadata": {"chunk_id": "gpu-fundamentals-001", "document_id": "gpu-fundamentals", "position": 1, "token_count": 77, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Overview of GPU Programming in Mojo"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#overview-of-gpu-programming-in-mojo"}}
{"chunk_id": "gpu-fundamentals-002", "document_id": "gpu-fundamentals", "content": "### GPU support in the Mojo Standard Library\n\nThe [`gpu`](/mojo/stdlib/gpu/) package of the Mojo Standard Library includes\nseveral subpackages for interacting with GPUs, with the\n[`gpu.host`](/mojo/stdlib/gpu/host/) package providing most of the commonly used\nAPIs. However, the [`sys`](/mojo/stdlib/sys/info/) package contains a few basic\nintrospection functions for determining whether a system has a supported GPU:", "position": 2, "token_count": 126, "has_code": false, "section_hierarchy": ["GPU support in the Mojo Standard Library"], "metadata": {"chunk_id": "gpu-fundamentals-002", "document_id": "gpu-fundamentals", "position": 2, "token_count": 126, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["GPU support in the Mojo Standard Library"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#gpu-support-in-the-mojo-standard-library"}}
{"chunk_id": "gpu-fundamentals-003", "document_id": "gpu-fundamentals", "content": "- [`has_accelerator()`](/mojo/stdlib/sys/info/has_accelerator): Returns `True`\n if the host system has an accelerator and `False` otherwise.\n- [`has_amd_gpu_accelerator()`](/mojo/stdlib/sys/info/has_amd_gpu_accelerator):\n Returns `True` if the host system has an AMD GPU and `False` otherwise.\n- [`has_nvidia_gpu_accelerator()`](/mojo/stdlib/sys/info/has_nvidia_gpu_accelerator):\n Returns `True` if the host system has an NVIDIA GPU and `False` otherwise.\n\nThese functions are useful for conditional compilation or execution depending on\nwhether a supported GPU is available.\n\n```mojo title=\"detect_gpu.mojo\"\nfrom sys import has_accelerator", "position": 3, "token_count": 210, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-003", "document_id": "gpu-fundamentals", "position": 3, "token_count": 210, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-004", "document_id": "gpu-fundamentals", "content": "These functions are useful for conditional compilation or execution depending on\nwhether a supported GPU is available.\n\n```mojo title=\"detect_gpu.mojo\"\nfrom sys import has_accelerator\n\ndef main():\n @parameter\n if has_accelerator():\n print(\"GPU detected\")\n # Enable GPU processing\n else:\n print(\"No GPU detected\")\n # Print error or fall back to CPU-only execution", "position": 4, "token_count": 91, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-004", "document_id": "gpu-fundamentals", "position": 4, "token_count": 91, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-005", "document_id": "gpu-fundamentals", "content": "```\n\n[note]\nMojo requires a [compatible GPU development\nenvironment](/max/faq/#gpu-requirements) to compile kernel functions, otherwise\nit raises a compile-time error. In this example, we're using the\n[`@parameter`](/mojo/manual/decorators/parameter) decorator to evaluate the\n`has_accelerator()` function at compile time and compile only the corresponding\nbranch of the `if` statement. As a result, if you don't have a compatible GPU\ndevelopment environment, you'll see the following message when you run the\nprogram:\n\n```output\nNo GPU detected\n```", "position": 5, "token_count": 145, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-005", "document_id": "gpu-fundamentals", "position": 5, "token_count": 145, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-006", "document_id": "gpu-fundamentals", "content": "### GPU programming model\n\nGPU programming follows a distinct pattern where work is divided between the CPU\nand GPU:\n\n- The CPU (host) manages program flow and coordinates GPU operations.\n- The GPU (device) executes parallel computations across many threads.\n- You must explicitly manage data exchange between host and device memory.\n\nA GPU program generally follows these steps:\n\n1. Initialize data in host (CPU) memory.\n2. Allocate device (GPU) memory and transfer data from host to device memory.\n3. Execute a kernel function on the GPU to process the data.\n4. Transfer results back from device to host memory.", "position": 6, "token_count": 138, "has_code": false, "section_hierarchy": ["GPU programming model"], "metadata": {"chunk_id": "gpu-fundamentals-006", "document_id": "gpu-fundamentals", "position": 6, "token_count": 138, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["GPU programming model"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#gpu-programming-model"}}
{"chunk_id": "gpu-fundamentals-007", "document_id": "gpu-fundamentals", "content": "This process typically runs asynchronously, allowing the CPU to perform other\ntasks while the GPU processes data. Any time that the CPU needs to ensure that\nthe GPU has completed an operation, such as before it copies kernel results from\ndevice memory, it must first explicitly synchronize with the GPU as described in\n[Asynchronous operation and synchronizing the CPU and\nGPU](#asynchronous-operation-and-synchronizing-the-cpu-and-gpu).\n\nA simple example helps to understand this programming model. We'll not go into\ndetail about the specific APIs at this point other than the included comments,\nbut all of the types, functions, and methods are discussed in more detail in\nlater sections of this document.\n\n```mojo title=\"scalar_add.mojo\"\nfrom gpu.host import DeviceContext\nfrom gpu.id import block_dim, block_idx, thread_idx\nfrom math import iota\nfrom sys import exit\nfrom sys.info import has_accelerator\n\nalias num_elements = 20", "position": 7, "token_count": 235, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-007", "document_id": "gpu-fundamentals", "position": 7, "token_count": 235, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-008", "document_id": "gpu-fundamentals", "content": "alias num_elements = 20\n\nfn scalar_add(vector: UnsafePointer[Float32], size: Int, scalar: Float32):\n \"\"\"\n Kernel function to add a scalar to all elements of a vector.\n\n This kernel function adds a scalar value to each element of a vector stored\n in GPU memory. The input vector is modified in place.\n\n Args:\n vector: Pointer to the input vector.\n size: Number of elements in the vector.\n scalar: Scalar to add to the vector.\n\n \"\"\"\n\n # Calculate the global thread index within the entire grid. Each thread\n # processes one element of the vector.\n #\n # block_idx.x: index of the current thread block.\n # block_dim.x: number of threads per block.\n # thread_idx.x: index of the current thread within its block.\n idx = block_idx.x * block_dim.x + thread_idx.x", "position": 8, "token_count": 205, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-008", "document_id": "gpu-fundamentals", "position": 8, "token_count": 205, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-009", "document_id": "gpu-fundamentals", "content": "# Bounds checking: ensure we don't access memory beyond the vector size.\n # This is crucial when the number of threads doesn't exactly match vector\n # size.\n if idx < UInt(size):\n # Each thread adds the scalar to its corresponding vector element\n # This operation happens in parallel across all GPU threads\n vector[idx] += scalar\n\ndef main():\n @parameter\n if not has_accelerator():\n print(\"No GPUs detected\")\n exit(0)\n else:\n # Initialize GPU context for device 0 (default GPU device).\n ctx = DeviceContext()\n\n # Create a buffer in host (CPU) memory to store our input data\n host_buffer = ctx.enqueue_create_host_buffer[DType.float32](\n num_elements\n )\n\n # Wait for buffer creation to complete.\n ctx.synchronize()", "position": 9, "token_count": 193, "has_code": false, "section_hierarchy": ["Bounds checking: ensure we don't access memory beyond the vector size."], "metadata": {"chunk_id": "gpu-fundamentals-009", "document_id": "gpu-fundamentals", "position": 9, "token_count": 193, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Bounds checking: ensure we don't access memory beyond the vector size."], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#bounds-checking-ensure-we-dont-access-memory-beyond-the-vector-size"}}
{"chunk_id": "gpu-fundamentals-010", "document_id": "gpu-fundamentals", "content": "# Wait for buffer creation to complete.\n ctx.synchronize()\n\n # Fill the host buffer with sequential numbers (0, 1, 2, ..., size-1).\n iota(host_buffer.unsafe_ptr(), num_elements)\n print(\"Original host buffer:\", host_buffer)\n\n # Create a buffer in device (GPU) memory to store data for computation.\n device_buffer = ctx.enqueue_create_buffer[DType.float32](num_elements)\n\n # Copy data from host memory to device memory for GPU processing.\n ctx.enqueue_copy(src_buf=host_buffer, dst_buf=device_buffer)\n\n # Compile the scalar_add kernel function for execution on the GPU.\n scalar_add_kernel = ctx.compile_function[scalar_add]()", "position": 10, "token_count": 201, "has_code": false, "section_hierarchy": ["Wait for buffer creation to complete."], "metadata": {"chunk_id": "gpu-fundamentals-010", "document_id": "gpu-fundamentals", "position": 10, "token_count": 201, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Wait for buffer creation to complete."], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#wait-for-buffer-creation-to-complete"}}
{"chunk_id": "gpu-fundamentals-011", "document_id": "gpu-fundamentals", "content": "# Compile the scalar_add kernel function for execution on the GPU.\n scalar_add_kernel = ctx.compile_function[scalar_add]()\n\n # Launch the GPU kernel with the following arguments:\n #\n # - device_buffer: GPU memory containing our vector data\n # - num_elements: number of elements in the vector\n # - Float32(20.0): the scalar value to add to each element\n # - grid_dim=1: use 1 thread block\n # - block_dim=num_elements: use 'num_elements' threads per block (one\n # thread per vector element)\n ctx.enqueue_function(\n scalar_add_kernel,\n device_buffer,\n num_elements,\n Float32(20.0),\n grid_dim=1,\n block_dim=num_elements,\n )\n\n # Copy the computed results back from device memory to host memory.\n ctx.enqueue_copy(src_buf=device_buffer, dst_buf=host_buffer)", "position": 11, "token_count": 230, "has_code": false, "section_hierarchy": ["Compile the scalar_add kernel function for execution on the GPU."], "metadata": {"chunk_id": "gpu-fundamentals-011", "document_id": "gpu-fundamentals", "position": 11, "token_count": 230, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Compile the scalar_add kernel function for execution on the GPU."], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#compile-the-scalaradd-kernel-function-for-execution-on-the-gpu"}}
{"chunk_id": "gpu-fundamentals-012", "document_id": "gpu-fundamentals", "content": "# Copy the computed results back from device memory to host memory.\n ctx.enqueue_copy(src_buf=device_buffer, dst_buf=host_buffer)\n\n # Wait for all GPU operations to complete.\n ctx.synchronize()\n\n # Display the final results after GPU computation.\n print(\"Modified host buffer:\", host_buffer)", "position": 12, "token_count": 86, "has_code": false, "section_hierarchy": ["Copy the computed results back from device memory to host memory."], "metadata": {"chunk_id": "gpu-fundamentals-012", "document_id": "gpu-fundamentals", "position": 12, "token_count": 86, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Copy the computed results back from device memory to host memory."], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#copy-the-computed-results-back-from-device-memory-to-host-memory"}}
{"chunk_id": "gpu-fundamentals-013", "document_id": "gpu-fundamentals", "content": "```\n\nThis application produces the following output:\n\n```output\nOriginal host buffer: HostBuffer([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0])\nModified host buffer: HostBuffer([20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0])\n```", "position": 13, "token_count": 199, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-013", "document_id": "gpu-fundamentals", "position": 13, "token_count": 199, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-014", "document_id": "gpu-fundamentals", "content": "## Accessing and managing GPUs with `DeviceContext`\n\nThe [`gpu.host`](/mojo/stdlib/gpu/host/) package includes the\n[`DeviceContext`](/mojo/stdlib/gpu/host/device_context/DeviceContext/) struct,\nwhich represents a logical instance of a GPU device. It provides methods for\nallocating memory on the device, copying data between the host CPU and the GPU,\nand compiling and running functions (also known as *kernels*) on the device.", "position": 14, "token_count": 126, "has_code": false, "section_hierarchy": ["Accessing and managing GPUs with `DeviceContext`"], "metadata": {"chunk_id": "gpu-fundamentals-014", "document_id": "gpu-fundamentals", "position": 14, "token_count": 126, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Accessing and managing GPUs with `DeviceContext`"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#accessing-and-managing-gpus-with-devicecontext"}}
{"chunk_id": "gpu-fundamentals-015", "document_id": "gpu-fundamentals", "content": "### Creating an instance of `DeviceContext` to access a GPU\n\nMojo supports systems with multiple GPUs. GPUs are uniquely identified by\ninteger indices starting with `0`, which is considered the \"default\" device. You\ncan determine the number of GPUs available by invoking the\n[`DeviceContext.number_of_devices()`](/mojo/stdlib/gpu/host/device_context/DeviceContext#number_of_devices)\nstatic method.\n\nThe `DeviceContext()` constructor returns an instance for interacting with a\nspecified GPU. It accepts two optional arguments:\n\n- `device_id`: An integer index of a specific GPU on the system. The default\n value of 0 refers to the \"default\" GPU for the system.\n- `api`: A `String` specifying a particular vendor's API. \"cuda\" (NVIDIA) and\n \"hip\" (AMD) are currently supported.\n\nIf your system doesn't have a supported GPU — or doesn't have a GPU matching the\n`device_id` or `api`, if provided — then the constructor raises an error.", "position": 15, "token_count": 253, "has_code": false, "section_hierarchy": ["Creating an instance of `DeviceContext` to access a GPU"], "metadata": {"chunk_id": "gpu-fundamentals-015", "document_id": "gpu-fundamentals", "position": 15, "token_count": 253, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Creating an instance of `DeviceContext` to access a GPU"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#creating-an-instance-of-devicecontext-to-access-a-gpu"}}
{"chunk_id": "gpu-fundamentals-016", "document_id": "gpu-fundamentals", "content": "### Asynchronous operation and synchronizing the CPU and GPU\n\nTypical CPU-GPU interaction is asynchronous, allowing the GPU to process tasks\nwhile the CPU is busy with other work. Each `DeviceContext` has an associated\nstream of queued operations to execute on the GPU. Operations within a stream\nexecute in the order they are enqueued.\n\nThe\n[`synchronize()`](/mojo/stdlib/gpu/host/device_context/DeviceContext#synchronize)\nmethod blocks execution of the current CPU thread until all queued operations on\nthe associated `DeviceContext` stream have completed. Most commonly, you use\nthis to wait until the result of a kernel function is copied from device memory\nto host memory before accessing it on the host.", "position": 16, "token_count": 179, "has_code": false, "section_hierarchy": ["Asynchronous operation and synchronizing the CPU and GPU"], "metadata": {"chunk_id": "gpu-fundamentals-016", "document_id": "gpu-fundamentals", "position": 16, "token_count": 179, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Asynchronous operation and synchronizing the CPU and GPU"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#asynchronous-operation-and-synchronizing-the-cpu-and-gpu"}}
{"chunk_id": "gpu-fundamentals-017", "document_id": "gpu-fundamentals", "content": "## Kernel functions\n\nA GPU *kernel* is simply a function that runs on a GPU, executing a specific\ncomputation on a large dataset in parallel across thousands or millions of\n*threads*. You specify the number of threads when you execute a kernel function,\nand all threads run the same kernel function. However, the GPU assigns a unique\nthread index for each thread, and you use the thread index to determine which\ndata elements an individual thread should process.", "position": 17, "token_count": 96, "has_code": false, "section_hierarchy": ["Kernel functions"], "metadata": {"chunk_id": "gpu-fundamentals-017", "document_id": "gpu-fundamentals", "position": 17, "token_count": 96, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Kernel functions"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#kernel-functions"}}
{"chunk_id": "gpu-fundamentals-018", "document_id": "gpu-fundamentals", "content": "### Multidimensional grids and thread organization\n\nAs discussed in [GPU execution\nmodel](/mojo/manual/gpu/architecture#gpu-execution-model), a *grid* is the\ntop-level organizational structure of the threads executing a kernel function on\na GPU. A grid consists of multiple *thread blocks*, which are organized across\none, two, or three dimensions. Each thread block is further divided into\nindividual threads, which are in turn organized across one, two, or three\ndimensions.\n\nYou specify the grid and thread block dimensions with the `grid_dim` and\n`block_dim` keyword arguments when you enqueue a kernel function to execute\nusing the\n[`enqueue_function()`](/mojo/stdlib/gpu/host/device_context/DeviceContext/#enqueue_function)\nmethod. For example:\n\n```mojo", "position": 18, "token_count": 195, "has_code": true, "section_hierarchy": ["Multidimensional grids and thread organization"], "metadata": {"chunk_id": "gpu-fundamentals-018", "document_id": "gpu-fundamentals", "position": 18, "token_count": 195, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Multidimensional grids and thread organization"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#multidimensional-grids-and-thread-organization"}}
{"chunk_id": "gpu-fundamentals-019", "document_id": "gpu-fundamentals", "content": "# Enqueue the print_threads() kernel function\nctx.enqueue_function[print_threads](\n grid_dim=(2, 2, 1), # 2x2x1 blocks per grid\n block_dim=(4, 4, 2), # 4x4x2 threads per block\n)", "position": 19, "token_count": 71, "has_code": false, "section_hierarchy": ["Enqueue the print_threads() kernel function"], "metadata": {"chunk_id": "gpu-fundamentals-019", "document_id": "gpu-fundamentals", "position": 19, "token_count": 71, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Enqueue the print_threads() kernel function"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#enqueue-the-printthreads-kernel-function"}}
{"chunk_id": "gpu-fundamentals-020", "document_id": "gpu-fundamentals", "content": "```\n\nFor both `grid_dim` and `block_dim`, you express the size in the `x`, `y`, and\n`z` dimensions as a [`Dim`](/mojo/stdlib/gpu/host/dim/Dim/) or a `Tuple`. The\n`y` and `z` dimensions default to 1 if you don't explicitly provide them (that\nis, `(2, 2)` is treated as `(2, 2, 1)` and `(8,)` is treated as `(8, 1, 1)`).\nYou can also provide just an `Int` value to specify only the `x` dimension (that\nis, `64` is treated as `(64, 1, 1)`).\n\n<figure>\n\n![](../images/gpu/multidimensional-grid.png#light)\n![](../images/gpu/multidimensional-grid-dark.png#dark)", "position": 20, "token_count": 226, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-020", "document_id": "gpu-fundamentals", "position": 20, "token_count": 226, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-021", "document_id": "gpu-fundamentals", "content": "<figcaption><b>Figure 1.</b> Organization of thread blocks and threads within a\ngrid. </figcaption>\n\n</figure>\n\nFrom within a kernel function, you can access the grid and thread block\ndimensions and the assigned thread block and thread indices of the individual\nthreads executing the kernel using the following structures:", "position": 21, "token_count": 72, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-021", "document_id": "gpu-fundamentals", "position": 21, "token_count": 72, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-022", "document_id": "gpu-fundamentals", "content": "| Struct alias | Description |\n| --- | --- |\n| [`grid_dim`](/mojo/stdlib/gpu/id/#grid_dim) | Dimensions of the grid as `x`, `y`, and `z` values (for example, `grid_dim.y`). |\n| [`block_dim`](/mojo/stdlib/gpu/id/#block_dim) | Dimensions of the thread block as `x`, `y`, and `z` values. |\n| [`block_idx`](/mojo/stdlib/gpu/id/#block_idx) | Index of the block within the grid as `x`, `y`, and `z` values. |\n| [`thread_idx`](/mojo/stdlib/gpu/id/#thread_idx) | Index of the thread within the block as `x`, `y`, and `z` values. |", "position": 22, "token_count": 230, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-022", "document_id": "gpu-fundamentals", "position": 22, "token_count": 230, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-023", "document_id": "gpu-fundamentals", "content": "| [`global_idx`](/mojo/stdlib/gpu/id/#global_idx) | The global offset of the thread as `x`, `y`, and `z` values. That is, `global_idx.x = block_dim.x * block_idx.x + thread_idx.x`, `global_idx.y = block_dim.y * block_idx.y + thread_idx.y`, and `global_idx.z = block_dim.z * block_idx.z + thread_idx.z`. |", "position": 23, "token_count": 144, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-023", "document_id": "gpu-fundamentals", "position": 23, "token_count": 144, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-024", "document_id": "gpu-fundamentals", "content": "Here is a complete example showing a kernel function that simply prints the\nthread block index, thread index, and global index for each thread executed.\n\n```mojo title=\"print_threads.mojo\"\nfrom gpu.host import DeviceContext\nfrom gpu.id import block_dim, block_idx, grid_dim, global_idx, thread_idx\nfrom sys import exit, has_accelerator\n\nfn print_threads():\n \"\"\"Print thread block and thread indices.\"\"\"", "position": 24, "token_count": 110, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-024", "document_id": "gpu-fundamentals", "position": 24, "token_count": 110, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-025", "document_id": "gpu-fundamentals", "content": "fn print_threads():\n \"\"\"Print thread block and thread indices.\"\"\"\n\n print(\n \"block_idx: [\",\n block_idx.x,\n block_idx.y,\n block_idx.z,\n \"]\\tthread_idx: [\",\n thread_idx.x,\n thread_idx.y,\n thread_idx.z,\n \"]\\tglobal_idx: [\",\n global_idx.x,\n global_idx.y,\n global_idx.z,\n \"]\\tcalculated global_idx: [\",\n block_dim.x * block_idx.x + thread_idx.x,\n block_dim.y * block_idx.y + thread_idx.y,\n block_dim.z * block_idx.z + thread_idx.z,\n \"]\",\n )", "position": 25, "token_count": 204, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-025", "document_id": "gpu-fundamentals", "position": 25, "token_count": 204, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-026", "document_id": "gpu-fundamentals", "content": "def main():\n @parameter\n if not has_accelerator():\n print(\"No GPU detected\")\n exit(0)\n else:\n # Initialize GPU context for device 0 (default GPU device).\n ctx = DeviceContext()\n\n ctx.enqueue_function[print_threads](\n grid_dim=(2, 2, 1), # 2x2x1 blocks per grid\n block_dim=(4, 4, 2), # 4x4x2 threads per block\n )\n\n ctx.synchronize()\n print(\"Done\")", "position": 26, "token_count": 128, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-026", "document_id": "gpu-fundamentals", "position": 26, "token_count": 128, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-027", "document_id": "gpu-fundamentals", "content": "```\n\nThis application produces output similar to this (with the output order\nindeterminate because of the concurrent execution of multiple threads):\n\n```output\nblock_idx: [ 0 1 0 ]\tthread_idx: [ 0 0 0 ]\tglobal_idx: [ 0 4 0 ]\tcalculated global_idx: [ 0 4 0 ]\nblock_idx: [ 0 1 0 ]\tthread_idx: [ 1 0 0 ]\tglobal_idx: [ 1 4 0 ]\tcalculated global_idx: [ 1 4 0 ]\n...\nblock_idx: [ 1 1 0 ]\tthread_idx: [ 2 3 1 ]\tglobal_idx: [ 6 7 1 ]\tcalculated global_idx: [ 6 7 1 ]\nblock_idx: [ 1 1 0 ]\tthread_idx: [ 3 3 1 ]\tglobal_idx: [ 7 7 1 ]\tcalculated global_idx: [ 7 7 1 ]\nDone\n```", "position": 27, "token_count": 205, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-027", "document_id": "gpu-fundamentals", "position": 27, "token_count": 205, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-028", "document_id": "gpu-fundamentals", "content": "### Writing a kernel function\n\nKernel functions must be\n[non-raising](/mojo/manual/functions/#raising-and-non-raising-functions).\nThis means that you must define them using the `fn` keyword and not use the\n`raises` keyword. (The Mojo compiler *always* treats a function declared with\n`def` as a raising function, even if the body of the function doesn't contain\nany code that could raise an error.)", "position": 28, "token_count": 103, "has_code": false, "section_hierarchy": ["Writing a kernel function"], "metadata": {"chunk_id": "gpu-fundamentals-028", "document_id": "gpu-fundamentals", "position": 28, "token_count": 103, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Writing a kernel function"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#writing-a-kernel-function"}}
{"chunk_id": "gpu-fundamentals-029", "document_id": "gpu-fundamentals", "content": "Argument values must be of types that conform to the\n[`DevicePassable`](/mojo/stdlib/builtin/device_passable/DevicePassable/) trait.\nAdditionally, a kernel function can't have a return value. Instead, you must\nwrite any result of a kernel function to a memory buffer passed in as an\nargument. The next two sections, [Passing data between CPU and\nGPU](#passing-data-between-cpu-and-gpu) and\n[`DeviceBuffer` and `HostBuffer`](#devicebuffer-and-hostbuffer) go into more\ndetail on how to pass values to a kernel function and get back results.", "position": 29, "token_count": 149, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-029", "document_id": "gpu-fundamentals", "position": 29, "token_count": 149, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-030", "document_id": "gpu-fundamentals", "content": "As discussed in [GPU execution\nmodel](/mojo/manual/gpu/architecture#gpu-execution-model), when the GPU executes\na kernel, it assigns the grid's thread blocks to various streaming\nmultiprocessors (SMs) for execution. The SM then divides the thread block into\nsubsets of threads called a *warp*. The size of a warp depends on the GPU\narchitecture, but most modern GPUs currently use a warp size of 32 or 64\nthreads.\n\n<figure>\n\n![](../images/gpu/grid-hierarchy.png#light)\n![](../images/gpu/grid-hierarchy-dark.png#dark)\n\n<figcaption><b>Figure 2.</b> Hierarchy of threads running on a GPU, showing the\nrelationship of the grid, thread blocks, warps, and individual threads, based\non <cite>HIP Programming Guide</cite> ©2023-2025 Advanced Micro Devices,\nInc.</figcaption>\n\n</figure>", "position": 30, "token_count": 229, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-030", "document_id": "gpu-fundamentals", "position": 30, "token_count": 229, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-031", "document_id": "gpu-fundamentals", "content": "</figure>\n\nIf a thread block contains a number of threads not evenly divisible by the warp\nsize, the SM creates a partially filled final warp that still consumes the full\nwarp's resources. For example, if a thread block has 100 threads and the warp\nsize is 32, the SM creates:\n\n- 3 full warps of 32 threads each (96 threads total).\n- 1 partial warp with only 4 active threads but still occupying a full warp's\n worth of resources (32 thread slots).\n\nBecause of this execution model, you must ensure that the threads in your kernel\ndon't attempt to access out-of-bounds data. Otherwise, your kernel might crash\nor produce incorrect results. For example, if you pass a 2,000-element vector to\na kernel that you execute with single-dimension thread blocks of 512 threads\neach, and each thread is responsible for processing one element, your kernel\ncould perform a boundary check like this to ensure that it doesn't attempt to\nprocess out-of-bounds elements:\n\n```mojo\nfrom gpu.id import global_idx", "position": 31, "token_count": 225, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-031", "document_id": "gpu-fundamentals", "position": 31, "token_count": 225, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-032", "document_id": "gpu-fundamentals", "content": "```mojo\nfrom gpu.id import global_idx\n\nfn process_vector(vector: UnsafePointer[Float32], size: Int):\n if global_idx.x < size:\n # Process vector[global_idx.x] in some way", "position": 32, "token_count": 61, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-032", "document_id": "gpu-fundamentals", "position": 32, "token_count": 61, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-033", "document_id": "gpu-fundamentals", "content": "```", "position": 33, "token_count": 5, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-033", "document_id": "gpu-fundamentals", "position": 33, "token_count": 5, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-034", "document_id": "gpu-fundamentals", "content": "### Passing data between CPU and GPU\n\nAll values passed to a kernel function must be of types that conform to the\n[`DevicePassable`](/mojo/stdlib/builtin/device_passable/DevicePassable/) trait.\nThe trait declares an [associated\nalias](/mojo/manual/traits/#associated-aliases-for-generics) named `device_type`\nthat maps the type as used on the CPU host to a corresponding type used on the\nGPU device.", "position": 34, "token_count": 111, "has_code": false, "section_hierarchy": ["Passing data between CPU and GPU"], "metadata": {"chunk_id": "gpu-fundamentals-034", "document_id": "gpu-fundamentals", "position": 34, "token_count": 111, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Passing data between CPU and GPU"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#passing-data-between-cpu-and-gpu"}}
{"chunk_id": "gpu-fundamentals-035", "document_id": "gpu-fundamentals", "content": "As an example,\n[`DeviceBuffer`](/mojo/stdlib/gpu/host/device_context/DeviceBuffer) is a\nhost-side representation of a buffer located in the GPU's global memory space.\nBut it defines its `device_type` associated alias as `UnsafePointer`, so the\ndata represented by a `DeviceBuffer` is actually passed to the kernel function\nas a value of type\n[`UnsafePointer`](/mojo/stdlib/memory/unsafe_pointer/UnsafePointer). The next\nsection, [`DeviceBuffer` and `HostBuffer` ](#devicebuffer-and-hostbuffer),\ndescribes in more detail how to allocate memory buffers on the host and device\nand to exchange blocks of data between host and device.\n\nThe following table lists the most commonly used types in the Mojo Standard\nLibrary that conform to the `DevicePassable` trait.", "position": 35, "token_count": 204, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-035", "document_id": "gpu-fundamentals", "position": 35, "token_count": 204, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-036", "document_id": "gpu-fundamentals", "content": "The following table lists the most commonly used types in the Mojo Standard\nLibrary that conform to the `DevicePassable` trait.\n\n| Host type | Device Type | Description |\n| --- | --- | --- |\n| [`Int`](/mojo/stdlib/builtin/int/Int) | `Int` | Signed integer |\n| [`SIMD[dtype, width]`](/mojo/stdlib/builtin/simd/SIMD) | `SIMD[dtype, width]` | Small vector backed by a hardware vector element |\n| [`DeviceBuffer[dtype]`](/mojo/stdlib/gpu/host/device_context/DeviceBuffer) | [`UnsafePointer[SIMD[dtype, 1]]`](/mojo/stdlib/memory/unsafe_pointer/UnsafePointer/) | Memory buffer of `dtype` values |", "position": 36, "token_count": 209, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-036", "document_id": "gpu-fundamentals", "position": 36, "token_count": 209, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-037", "document_id": "gpu-fundamentals", "content": "Additionally, you can take advantage of Mojo's support for [implicit\nconversion](/mojo/manual/lifecycle/life#constructors-and-implicit-conversion) to\nuse types that can convert to those listed above. A common example of this is\n[`LayoutTensor`](/mojo/kernels/layout/layout_tensor/LayoutTensor/), which\nprovides powerful abstractions for manipulating multi-dimensional data. For\nmore information on `LayoutTensor`, see the\n[Using `LayoutTensor`](/mojo/manual/layout/tensors) section of the Mojo Manual.", "position": 37, "token_count": 130, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-037", "document_id": "gpu-fundamentals", "position": 37, "token_count": 130, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-038", "document_id": "gpu-fundamentals", "content": "### `DeviceBuffer` and `HostBuffer`\n\nThis section describes how to use `DeviceBuffer` and `HostBuffer` to allocate\nmemory on the device and host respectively, and to copy data between device and\nhost memory.", "position": 38, "token_count": 55, "has_code": false, "section_hierarchy": ["`DeviceBuffer` and `HostBuffer`"], "metadata": {"chunk_id": "gpu-fundamentals-038", "document_id": "gpu-fundamentals", "position": 38, "token_count": 55, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["`DeviceBuffer` and `HostBuffer`"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#devicebuffer-and-hostbuffer"}}
{"chunk_id": "gpu-fundamentals-039", "document_id": "gpu-fundamentals", "content": "#### Creating a `DeviceBuffer`\n\nThe\n[`DeviceBuffer`](/mojo/stdlib/gpu/host/device_context/DeviceBuffer)\ntype represents a block of device memory associated with a particular\n`DeviceContext`. Specifically, the buffer is located in the device's *global\nmemory* space. As such, the buffer is accessible by all threads of all kernel\nfunctions executed by the `DeviceContext`.\n\nAs discussed in [Passing data between CPU and\nGPU](#passing-data-between-cpu-and-gpu), `DeviceBuffer` is the type used by the\n**host** to allocate the buffer and to copy data between the host and device.\nBut when you pass a `DeviceBuffer` to a kernel function, the argument received\nby the function is of type `UnsafePointer`. Attempting to use the `DeviceBuffer`\ntype directly from within a kernel function results in an error.", "position": 39, "token_count": 210, "has_code": false, "section_hierarchy": ["Creating a `DeviceBuffer`"], "metadata": {"chunk_id": "gpu-fundamentals-039", "document_id": "gpu-fundamentals", "position": 39, "token_count": 210, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Creating a `DeviceBuffer`"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#creating-a-devicebuffer"}}
{"chunk_id": "gpu-fundamentals-040", "document_id": "gpu-fundamentals", "content": "The\n[`DeviceContext.enqueue_create_buffer()`](/mojo/stdlib/gpu/host/device_context/DeviceContext#enqueue_create_buffer)\nmethod creates a `DeviceBuffer` associated with that `DeviceContext`. It accepts\nthe data type as a compile-time [`DType`](/mojo/stdlib/builtin/dtype/DType/)\nparameter and the size of the buffer as a run-time argument. So to create a\nbuffer for 1,024 [`Float32`](/mojo/stdlib/builtin/simd/#float32) values, you\nwould execute:\n\n```mojo\ndevice_buffer = ctx.enqueue_create_buffer[Float32](1024)", "position": 40, "token_count": 181, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-040", "document_id": "gpu-fundamentals", "position": 40, "token_count": 181, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-041", "document_id": "gpu-fundamentals", "content": "```\n\nAs the method name implies, this method is asynchronous and enqueues the\noperation on the `DeviceContext`'s associated [stream of queued\noperations](#asynchronous-operation-and-synchronizing-the-cpu-and-gpu).", "position": 41, "token_count": 69, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-041", "document_id": "gpu-fundamentals", "position": 41, "token_count": 69, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-042", "document_id": "gpu-fundamentals", "content": "#### Creating a `HostBuffer`\n\nThe [`HostBuffer`](/mojo/stdlib/gpu/host/device_context/HostBuffer) type is\nanalogous to `DeviceBuffer`, but represents a block of host memory associated\nwith a particular `DeviceContext`. It supports methods for transferring data\nbetween host and device memory, as well as a basic set of methods for accessing\ndata elements by index and for printing the buffer.", "position": 42, "token_count": 102, "has_code": false, "section_hierarchy": ["Creating a `HostBuffer`"], "metadata": {"chunk_id": "gpu-fundamentals-042", "document_id": "gpu-fundamentals", "position": 42, "token_count": 102, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Creating a `HostBuffer`"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#creating-a-hostbuffer"}}
{"chunk_id": "gpu-fundamentals-043", "document_id": "gpu-fundamentals", "content": "The\n[`DeviceContext.enqueue_create_host_buffer()`](/mojo/stdlib/gpu/host/device_context/DeviceContext#enqueue_create_host_buffer)\nmethod accepts the data type as a compile-time\n[`DType`](/mojo/stdlib/builtin/dtype/DType/) parameter and the size of the\nbuffer as a run-time argument and returns a `HostBuffer`. As with all\n`DeviceContext` methods whose name starts with `enqueue_`, the method is\nasynchronous and returns immediately, adding the operation to the queue to be\nexecuted by the `DeviceContext`. Therefore, you need to call the `synchronize()`\nmethod to ensure that the operation has completed before you write to or read\nfrom the `HostBuffer` object.\n\n```mojo\ndevice_buffer = ctx.enqueue_create_host_buffer[Float32](1024)", "position": 43, "token_count": 225, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-043", "document_id": "gpu-fundamentals", "position": 43, "token_count": 225, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-044", "document_id": "gpu-fundamentals", "content": "# Synchronize to wait until buffer is created before attempting to write to it\nctx.synchronize()", "position": 44, "token_count": 28, "has_code": false, "section_hierarchy": ["Synchronize to wait until buffer is created before attempting to write to it"], "metadata": {"chunk_id": "gpu-fundamentals-044", "document_id": "gpu-fundamentals", "position": 44, "token_count": 28, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Synchronize to wait until buffer is created before attempting to write to it"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#synchronize-to-wait-until-buffer-is-created-before-attempting-to-write-to-it"}}
{"chunk_id": "gpu-fundamentals-045", "document_id": "gpu-fundamentals", "content": "# Now it's safe to write to the buffer\nfor i in range(1024):\n device_buffer[i] = Float32(i * i)\n```", "position": 45, "token_count": 39, "has_code": true, "section_hierarchy": ["Now it's safe to write to the buffer"], "metadata": {"chunk_id": "gpu-fundamentals-045", "document_id": "gpu-fundamentals", "position": 45, "token_count": 39, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Now it's safe to write to the buffer"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#now-its-safe-to-write-to-the-buffer"}}
{"chunk_id": "gpu-fundamentals-046", "document_id": "gpu-fundamentals", "content": "#### Copying data between host and device memory\n\nThe\n[`enqueue_copy()`](/mojo/stdlib/gpu/host/device_context/DeviceContext#enqueue_copy)\nmethod is overloaded to support copying from host to device, device to host, or\neven device to device for systems that have multiple GPUs. Typically, you'll use\nit to copy data that you've staged in a `HostBuffer` to a `DeviceBuffer` before\nexecuting a kernel, and then from a `DeviceBuffer` to a `HostBuffer` to retrieve\nthe results of kernel execution. The `scalar_add.mojo` example in [GPU\nprogramming model](#gpu-programming-model) shows this pattern in action. In it,\nthe kernel function does an in-place modification of the buffer it receives as\nan argument and then reuses the original `HostBuffer` to copy the results back\nfrom the device. However, you can allocate a separate `DeviceBuffer` and\n`HostBuffer` for the result of a kernel function if you want to retain the\noriginal data.", "position": 46, "token_count": 247, "has_code": false, "section_hierarchy": ["Copying data between host and device memory"], "metadata": {"chunk_id": "gpu-fundamentals-046", "document_id": "gpu-fundamentals", "position": 46, "token_count": 247, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Copying data between host and device memory"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#copying-data-between-host-and-device-memory"}}
{"chunk_id": "gpu-fundamentals-047", "document_id": "gpu-fundamentals", "content": "In addition to copying data between a `HostBuffer` to a `DeviceBuffer`, you can\nuse an [`UnsafePointer`](/mojo/stdlib/memory/unsafe_pointer/UnsafePointer) as\nthe source or destination of a copy. However, the `UnsafePointer` must reference\nhost memory for this operation. Attempting to use an `UnsafePointer` referencing\ndevice memory results in an error. For example, this is useful if you have data\nalready staged in a data structure on the host that can expose the data through\nan `UnsafePointer`. In that case you would not need to copy the data from the\ndata structure to a `HostBuffer` before copying it to the `DeviceBuffer`.", "position": 47, "token_count": 158, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-047", "document_id": "gpu-fundamentals", "position": 47, "token_count": 158, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-048", "document_id": "gpu-fundamentals", "content": "Both `DeviceBuffer` and `HostBuffer` also include\n[`enqueue_copy_to()`](/mojo/stdlib/gpu/host/device_context/DeviceBuffer#enqueue_copy_to)\nand\n[`enqueue_copy_from()`](/mojo/stdlib/gpu/host/device_context/DeviceBuffer#enqueue_copy_from)\nmethods. These are simply convenience methods that call the `enqueue_copy()`\nmethod on their corresponding `DeviceContext`. For example, the following two\nmethod calls are interchangeable:\n\n```mojo\nctx.enqueue_copy(src_buf=host_buffer, dst_buf=device_buffer)", "position": 48, "token_count": 175, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-048", "document_id": "gpu-fundamentals", "position": 48, "token_count": 175, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-049", "document_id": "gpu-fundamentals", "content": "# Equivalent to:\nhost_buffer.enqueue_copy_to(dst=device_buffer)\n```\n\nFinally, as a convenience for testing or prototyping, you can use the\n[`DeviceBuffer.map_to_host()`](/mojo/stdlib/gpu/host/device_context/DeviceBuffer#map_to_host)\nmethod to create a host-accessible view of the device buffer's contents. This\nreturns `HostBuffer` as a [context\nmanager](/mojo/manual/errors#use-a-context-manager) that contains a copy of the\ndata from the corresponding `DeviceBuffer`. Additionally, any modifications that\nyou make to the `HostBuffer` are automatically copied back to the `DeviceBuffer`\nwhen the `with` statement exits. For example:\n\n```mojo\nctx = DeviceContext()\nlength = 1024\n\ninput_device = ctx.enqueue_create_buffer[DType.float32](length)", "position": 49, "token_count": 223, "has_code": true, "section_hierarchy": ["Equivalent to:"], "metadata": {"chunk_id": "gpu-fundamentals-049", "document_id": "gpu-fundamentals", "position": 49, "token_count": 223, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Equivalent to:"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#equivalent-to"}}
{"chunk_id": "gpu-fundamentals-050", "document_id": "gpu-fundamentals", "content": "# Initialize the input\n\nwith input_device.map_to_host() as input_host:\n for i in range(length):\n input_host[i] = Float32(i)\n```\n\nHowever, you should not use this in most production code because of the\nbidirectional copies and synchronization. The example above is equivalent to:\n\n```mojo\nctx = DeviceContext()\nlength = 1024\n\ninput_device = ctx.enqueue_create_buffer[DType.float32](length)\ninput_host = ctx.enqueue_create_host_buffer[DType.float32](length)\n\ninput_device.enqueue_copy_to(input_host)\nctx.synchronize()\n\nfor i in range(length):\n input_host[i] = Float32(i)\n\ninput_host.enqueue_copy_to(input_device)\nctx.synchronize()\n```", "position": 50, "token_count": 218, "has_code": true, "section_hierarchy": ["Initialize the input"], "metadata": {"chunk_id": "gpu-fundamentals-050", "document_id": "gpu-fundamentals", "position": 50, "token_count": 218, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Initialize the input"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#initialize-the-input"}}
{"chunk_id": "gpu-fundamentals-051", "document_id": "gpu-fundamentals", "content": "#### Deallocating memory buffers\n\nBoth `DeviceBuffer` and `HostBuffer` are subject to Mojo's standard ownership\nand lifecycle mechanisms. The Mojo compiler analyzes our program to determine\nthe last point that the owner of or a reference to an object is used and\nautomatically adds a call to the object's destructor. This means that you don't\nexplicitly call any method to free the memory represented by a `DeviceBuffer` or\n`HostBuffer` instance. See the [Ownership](/mojo/manual/values/ownership) and\n[Intro to value lifecycle](/mojo/manual/lifecycle) sections of the Mojo Manual\nfor more information on Mojo value ownership and value lifecycle management, and\nthe [Death of a value](/mojo/manual/lifecycle/death) section for a detailed\nexplanation of object destruction.", "position": 51, "token_count": 184, "has_code": false, "section_hierarchy": ["Deallocating memory buffers"], "metadata": {"chunk_id": "gpu-fundamentals-051", "document_id": "gpu-fundamentals", "position": 51, "token_count": 184, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Deallocating memory buffers"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#deallocating-memory-buffers"}}
{"chunk_id": "gpu-fundamentals-052", "document_id": "gpu-fundamentals", "content": "### Compiling and enqueuing a kernel function for execution\n\nThe\n[`compile_function()`](/mojo/stdlib/gpu/host/device_context/DeviceContext/#compile_function)\nmethod accepts a kernel function as a compile-time\n[parameter](/mojo/manual/parameters) and then compiles it for the associated\n`DeviceContext`. Then you can enqueue the compiled kernel for execution by\npassing it to the\n[`enqueue_function()`](/mojo/stdlib/gpu/host/device_context/DeviceContext/#enqueue_function)\nmethod. The example in the [GPU programming model](#gpu-programming-model)\ndemonstrated this pattern:\n\n```mojo title=\"scalar_add.mojo\"\n...\nscalar_add_kernel = ctx.compile_function[scalar_add]()", "position": 52, "token_count": 209, "has_code": true, "section_hierarchy": ["Compiling and enqueuing a kernel function for execution"], "metadata": {"chunk_id": "gpu-fundamentals-052", "document_id": "gpu-fundamentals", "position": 52, "token_count": 209, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Compiling and enqueuing a kernel function for execution"], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals#compiling-and-enqueuing-a-kernel-function-for-execution"}}
{"chunk_id": "gpu-fundamentals-053", "document_id": "gpu-fundamentals", "content": "```mojo title=\"scalar_add.mojo\"\n...\nscalar_add_kernel = ctx.compile_function[scalar_add]()\n\nctx.enqueue_function(\n scalar_add_kernel,\n device_buffer,\n num_elements,\n Float32(20.0),\n grid_dim=1,\n block_dim=num_elements,\n)", "position": 53, "token_count": 90, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-053", "document_id": "gpu-fundamentals", "position": 53, "token_count": 90, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-054", "document_id": "gpu-fundamentals", "content": "```\n\nWhen using a compiled kernel function like this, you execute it by calling\n`enqueue_function()` with the following arguments in this order:\n\n- The kernel function to execute.\n- Any additional arguments specified by the kernel function definition in the\n order specified by the function.\n- The grid dimensions using the `grid_dim` keyword argument.\n- The thread block dimensions using the `block_dim` keyword argument.\n\nRefer to the [Multidimensional grids and thread\norganization](#multidimensional-grids-and-thread-organization) section for more\ninformation on grid and thread block dimensions.\n\n[note]\nThe current implementation of `enqueue_function()` doesn't typecheck the\narguments to the compiled kernel function, which can lead to obscure run-time\nerrors if the argument ordering, types, or count doesn't match the kernel\nfunction's definition.", "position": 54, "token_count": 192, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-054", "document_id": "gpu-fundamentals", "position": 54, "token_count": 192, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-055", "document_id": "gpu-fundamentals", "content": "For compile-time typechecking, you can use the\n[`compile_function_checked()`](/mojo/stdlib/gpu/host/device_context/DeviceContext/#compile_function_checked)\nand\n[`enqueue_function_checked()`](/mojo/stdlib/gpu/host/device_context/DeviceContext/#enqueue_function_checked)\nmethods.\n\nHere's the typechecked equivalent of the `scalar_add()` kernel compilation and\nenqueuing shown above:\n\n```mojo\nscalar_add_kernel = ctx.compile_function_checked[scalar_add, scalar_add]()\n\nctx.enqueue_function_checked(\n scalar_add_kernel,\n device_buffer,\n num_elements,\n Float32(20.0),\n grid_dim=1,\n block_dim=num_elements,\n)", "position": 55, "token_count": 213, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-055", "document_id": "gpu-fundamentals", "position": 55, "token_count": 213, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-056", "document_id": "gpu-fundamentals", "content": "```\n\nNote that `compile_function_checked()` currently requires the kernel function to\nbe provided *twice* as parameters. This requirement will be removed in a future\nAPI update, when typechecking will become the default behavior for both\n`compile_function()` and `enqueue_function()`.\n\nThe advantage of compiling the kernel as a separate step is that that you can\nexecute the same compiled kernel on the same device multiple times. This avoids\nthe overhead of compiling the kernel each time it's executed.\n\nIf your application needs to execute a kernel function only once, you can use an\noverloaded version of `enqueue_function()` that compiles the kernel and enqueues\nit in a single step. Therefore, the following is equivalent to the separate\ncalls to `compile_function()` and `enqueue_function()` shown above (note that\nthe kernel function is provided as a compile-time parameter in this case):", "position": 56, "token_count": 210, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-056", "document_id": "gpu-fundamentals", "position": 56, "token_count": 210, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
{"chunk_id": "gpu-fundamentals-057", "document_id": "gpu-fundamentals", "content": "```mojo\nctx.enqueue_function[scalar_add](\n device_buffer,\n num_elements,\n Float32(20.0),\n grid_dim=1,\n block_dim=num_elements,\n)\n```", "position": 57, "token_count": 57, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-fundamentals-057", "document_id": "gpu-fundamentals", "position": 57, "token_count": 57, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/fundamentals.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/fundamentals", "title": "GPU programming fundamentals", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/fundamentals"}}
