{"chunk_id": "gpu-block-and-warp-000", "document_id": "gpu-block-and-warp", "content": "When multiple GPU threads write to the same memory location without a defined\norder of execution, a *race condition* occurs. The final outcome of the\ncomputation becomes non-deterministic, depending on the scheduling and timing\nof execution of threads by the GPU hardware. Such bugs are notoriously\ndifficult to debug because they may not appear consistently in every run.\n\nTo write correct and robust parallel programs, you need explicit\nmechanisms to coordinate the execution of threads and manage the visibility of\ntheir memory operations. These mechanisms are known as *synchronization\nprimitives*. They are not merely performance optimizations; they are essential\ntools for correctness. Without them, threads operate in complete isolation,\nunable to safely share intermediate results, divide complex tasks, or perform\nthe collective computations that are the hallmark of high-performance GPU\nalgorithms.\n\nA *barrier* is a fundamental synchronization primitive that creates a meeting\npoint in the program where all participating threads must wait for each other.\nWhen a thread reaches a barrier, it pauses execution until every other thread\nin the group also arrives. This ensures that all threads proceed together past\nthe barrier, maintaining consistent state and preventing race conditions when\naccessing shared data.", "position": 0, "token_count": 245, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-000", "document_id": "gpu-block-and-warp", "position": 0, "token_count": 245, "has_code": false, "overlap_with_previous": false, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-001", "document_id": "gpu-block-and-warp", "content": "Mojo provides two complementary categories of GPU coordination tools.\n*Synchronization primitives* like `barrier()` and `syncwarp()` coordinate\nthread execution and enforce memory visibility, but they don't perform\ncomputation themselves—they're pure coordination mechanisms. In contrast,\n*collective operations* like reductions, broadcasts, and prefix sums combine\nsynchronization with common computational patterns: they coordinate threads\n*and* compute a result. Use synchronization primitives when you need explicit\ncontrol over when threads coordinate (such as managing access to shared memory\nbetween distinct phases of an algorithm), and use collective operations when\nyou need to aggregate or distribute data across threads (such as computing a\nsum or maximum across a thread block or warp). Both types of tools are\nessential for writing correct and efficient GPU code, and understanding when to\nuse each is key to building robust parallel algorithms.", "position": 1, "token_count": 185, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-001", "document_id": "gpu-block-and-warp", "position": 1, "token_count": 185, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-002", "document_id": "gpu-block-and-warp", "content": "This guide covers Mojo's low-level primitives for managing coordination at the\nthread block and warp levels. For foundational GPU architecture concepts and\ndetailed explanations of the GPU execution model, see\n[Intro to GPUs](/mojo/manual/gpu/architecture). For a discussion of basic kernel\ncreation and device management, see [GPU programming\nfundamentals](/mojo/manual/gpu/fundamentals).\n\nWe'll explore Mojo's synchronization and collective communication primitives\nfor coordinating parallel work on the GPU. Key topics include:", "position": 2, "token_count": 121, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-002", "document_id": "gpu-block-and-warp", "position": 2, "token_count": 121, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-003", "document_id": "gpu-block-and-warp", "content": "- [Block-level synchronization and operations](#block-level-synchronization-and-operations):\n How to coordinate all threads within a thread block using\n [`barrier()`](/mojo/stdlib/gpu/sync/sync/barrier) and block reduction\n operations from the\n [`gpu.primitives.block`](/mojo/stdlib/gpu/primitives/block) module.\n- [Warp-level operations](#warp-level-operations): How to perform fine-grained\n synchronization with [`syncwarp()`](/mojo/stdlib/gpu/sync/sync/syncwarp) and\n leverage high-speed data exchange using\n [`gpu.primitives.warp`](/mojo/stdlib/gpu/primitives/warp) primitives.\n- [Best practices and common pitfalls](#best-practices-and-common-pitfalls): How\n to use these primitives correctly to write reliable and portable GPU code.", "position": 3, "token_count": 232, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-003", "document_id": "gpu-block-and-warp", "position": 3, "token_count": 232, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-004", "document_id": "gpu-block-and-warp", "content": "## Block-level synchronization and operations\n\nThis section covers coordination mechanisms for all threads within a thread\nblock:\n\n- [The `barrier()` primitive](#the-barrier-primitive): The fundamental\n synchronization primitive that ensures all threads reach the same point\n before proceeding.\n- [Block-level reduction operations](#block-level-reduction-operations):\n Higher-level collective operations (`sum`, `max`, `min`, `broadcast`,\n `prefix_sum`) that combine synchronization with computation.\n- [Block synchronization example](#block-synchronization-example-tiled-matrix-multiplication):\n A complete tiled matrix multiplication demonstrating practical barrier usage.\n\nThese tools serve different but complementary purposes: `barrier()` is a pure\nsynchronization primitive for coordinating execution and memory visibility,\nwhile block reduction operations are collective computations that internally\nhandle their own synchronization. You can use `barrier()` to build custom\ncoordination patterns, or use block reductions when you need both coordination\nand computation together.", "position": 4, "token_count": 229, "has_code": false, "section_hierarchy": ["Block-level synchronization and operations"], "metadata": {"chunk_id": "gpu-block-and-warp-004", "document_id": "gpu-block-and-warp", "position": 4, "token_count": 229, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Block-level synchronization and operations"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#block-level-synchronization-and-operations"}}
{"chunk_id": "gpu-block-and-warp-005", "document_id": "gpu-block-and-warp", "content": "### The `barrier()` primitive\n\nThe [`gpu.sync.barrier()`](/mojo/stdlib/gpu/sync/sync/barrier) function is the\nprimary mechanism for coordinating all threads within a single thread block. It\ncreates a synchronization point in the kernel's execution flow that no thread\ncan pass until every other thread in its block has also reached that point.\n\nThe `barrier()` primitive does two things: it acts as both an execution barrier\nand a memory fence.\n\n- Execution barrier: As an execution barrier, `barrier()` ensures that the\n execution of all threads in a block is paused at that point in the program.\n The hardware scheduler will not allow any thread to proceed past the barrier\n until all threads in that block have signaled their arrival.", "position": 5, "token_count": 171, "has_code": false, "section_hierarchy": ["The `barrier()` primitive"], "metadata": {"chunk_id": "gpu-block-and-warp-005", "document_id": "gpu-block-and-warp", "position": 5, "token_count": 171, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["The `barrier()` primitive"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#the-barrier-primitive"}}
{"chunk_id": "gpu-block-and-warp-006", "document_id": "gpu-block-and-warp", "content": "- Memory fence: As a memory fence, `barrier()` enforces a strict ordering on\n memory operations. It guarantees that all writes to shared memory (and global\n memory, with respect to other threads in the same block) performed by any\n thread *before* the barrier are completed and made visible to all other\n threads in the block *after* they pass the barrier. This guarantee is what\n prevents race conditions when threads communicate via shared memory.\n\nThe most common use case for `barrier()` is managing access to the fast,\non-chip shared memory shared by all threads within a block. Here's how a\ntypical algorithm works:\n\n1. Threads in a block cooperatively load a segment of data from the high-latency\n global memory into a shared memory array. Each thread is responsible for\n loading one or more elements.\n\n2. A call to `barrier()` is made. This is essential to ensure that the entire\n data segment is fully loaded into shared memory before any thread attempts to\n use it.\n\n3. Threads perform computations, reading from and writing to the shared memory\n array. This phase leverages the low latency of shared memory to accelerate\n the algorithm.", "position": 6, "token_count": 239, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-006", "document_id": "gpu-block-and-warp", "position": 6, "token_count": 239, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-007", "document_id": "gpu-block-and-warp", "content": "3. Threads perform computations, reading from and writing to the shared memory\n array. This phase leverages the low latency of shared memory to accelerate\n the algorithm.\n\n4. If the computation itself involves multiple stages of shared memory\n communication, another `barrier()` call may be necessary to ensure the\n results of one stage are visible before the next begins.\n\n5. Finally, threads write their results from shared memory back to global\n memory.\n\ncaution Caution\n\nA `barrier()` must be encountered by all threads within a block to avoid a\ndeadlock. Placing a `barrier()` inside a conditional statement (such as an `if`\nor `else` block) is a common source of bugs. If the condition causes some\nthreads to execute the `barrier()` while others skip it, the threads that reach\nthe barrier will wait indefinitely for the other threads to arrive, causing the\nkernel to hang. Therefore, `barrier()` should be used in conditional code only\nif it is guaranteed that all threads in the block will evaluate the condition\nidentically and follow the same execution path.", "position": 7, "token_count": 221, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-007", "document_id": "gpu-block-and-warp", "position": 7, "token_count": 221, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-008", "document_id": "gpu-block-and-warp", "content": "The Mojo `barrier()` function is functionally equivalent to the\n`__syncthreads()` intrinsic in both NVIDIA CUDA and AMD HIP and\n`threadgroup_barrier(mem_flags::mem_threadgroup)` in Apple Metal, providing a\nportable syntax for this fundamental operation.\n\n[tip]\nFor fine-grained synchronization within a single warp, see\n[`syncwarp()`](#warp-level-synchronization), which provides faster coordination\nfor threads executing together in the same warp without requiring block-wide\nsynchronization.", "position": 8, "token_count": 132, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-008", "document_id": "gpu-block-and-warp", "position": 8, "token_count": 132, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-009", "document_id": "gpu-block-and-warp", "content": "### Block-level reduction operations\n\nIn addition to the basic `barrier()` primitive, Mojo provides higher-level\nblock-wide collective operations through the\n[`gpu.primitives.block`](/mojo/stdlib/gpu/primitives/block) module. These\noperations combine the coordination functionality of `barrier()` with common\ncomputational patterns, offering both convenience and performance benefits.\n\nThe `gpu.primitives.block` module includes several reduction primitives:", "position": 9, "token_count": 104, "has_code": false, "section_hierarchy": ["Block-level reduction operations"], "metadata": {"chunk_id": "gpu-block-and-warp-009", "document_id": "gpu-block-and-warp", "position": 9, "token_count": 104, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Block-level reduction operations"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#block-level-reduction-operations"}}
{"chunk_id": "gpu-block-and-warp-010", "document_id": "gpu-block-and-warp", "content": "- [`sum(val)`](/mojo/stdlib/gpu/primitives/block/sum): Computes the sum of `val`\n across all threads in the block.\n- [`max(val)`](/mojo/stdlib/gpu/primitives/block/max): Computes the maximum\n `val` across all threads in the block.\n- [`min(val)`](/mojo/stdlib/gpu/primitives/block/min): Computes the minimum\n `val` across all threads in the block.\n- [`broadcast(val, src_thread=0)`](/mojo/stdlib/gpu/primitives/block/broadcast):\n Broadcasts the value from `src_thread` to all other threads in the block.\n- [`prefix_sum[exclusive=False](val)`](/mojo/stdlib/gpu/primitives/block/prefix_sum):", "position": 10, "token_count": 219, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-010", "document_id": "gpu-block-and-warp", "position": 10, "token_count": 219, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-011", "document_id": "gpu-block-and-warp", "content": "- [`prefix_sum[exclusive=False](val)`](/mojo/stdlib/gpu/primitives/block/prefix_sum):\n Computes an inclusive (default) or exclusive prefix sum (scan) across threads\n in the block. A prefix sum transforms an input sequence into cumulative sums:\n given $[x_0, x_1, x_2, x_3]$, an *inclusive* scan produces $[x_0, x_0+x_1,\n x_0+x_1+x_2, x_0+x_1+x_2+x_3]$ where each thread receives the sum of all\n values up to and including its own, while an *exclusive* scan produces $[0,\n x_0, x_0+x_1, x_0+x_1+x_2]$ where each thread receives the sum of all values\n *before* it.", "position": 11, "token_count": 206, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-011", "document_id": "gpu-block-and-warp", "position": 11, "token_count": 206, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-012", "document_id": "gpu-block-and-warp", "content": "These operations automatically handle the necessary synchronization and shared\nmemory management internally, making them both easier to use correctly and\noften more efficient than manually implementing equivalent functionality with\n`barrier()` and shared memory operations.\n\ntip Tip\n\nUse `gpu.primitives.block` operations when you need to aggregate data across all\nthreads in a thread block (which may span multiple warps). Use\n`gpu.primitives.warp` operations, as described in\n[Warp-level reduction operations](#warp-level-reduction-operations), when you\nneed to aggregate only within a single warp, as they are significantly faster.\nFor algorithms that reduce large datasets, use a hybrid approach: first reduce\nwithin warps using `gpu.primitives.warp` primitives, then combine warp results\nusing `gpu.primitives.block` operations.", "position": 12, "token_count": 178, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-012", "document_id": "gpu-block-and-warp", "position": 12, "token_count": 178, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-013", "document_id": "gpu-block-and-warp", "content": "### Using block operations in practice\n\nBlock-level operations are commonly used in multi-stage algorithms where\nthreads must coordinate through shared memory. A typical pattern involves:\n\n1. Load phase: Threads cooperatively load data into shared memory\n2. Synchronize: Use `barrier()` to ensure all data is loaded\n3. Compute phase: Process data using shared memory\n4. Reduce phase: Use block reduction operations to aggregate results\n\nThis pattern appears in algorithms like tiled matrix multiplication, stencil\noperations, and parallel reductions, where the combination of shared memory\nand proper synchronization enables significant performance improvements over\nnaive approaches.", "position": 13, "token_count": 128, "has_code": false, "section_hierarchy": ["Using block operations in practice"], "metadata": {"chunk_id": "gpu-block-and-warp-013", "document_id": "gpu-block-and-warp", "position": 13, "token_count": 128, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Using block operations in practice"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#using-block-operations-in-practice"}}
{"chunk_id": "gpu-block-and-warp-014", "document_id": "gpu-block-and-warp", "content": "### Block synchronization example: tiled matrix multiplication\n\nMatrix multiplication benefits from a technique called *tiling*, where we break\nlarge matrices into smaller tiles that fit in the GPU's fast shared memory.\nInstead of repeatedly reading from slow global memory, threads in a block\ncooperatively load a tile into shared memory once, then all threads can access\nit multiple times. This creates a classic *producer-consumer* pattern: threads\nwork together to load data (producer phase), then all threads use that data to\ncompute results (consumer phase). Without proper synchronization between these\nphases, the algorithm produces incorrect results. For a deeper understanding of\nthe tiling strategy, see\n[this section of our blog post on optimizing matrix multiplication on NVIDIA's\nBlackwell](https://www.modular.com/blog/matrix-multiplication-on-nvidias-blackwell-part-2-using-hardware-features-to-optimize-matmul#shared-memory).\n\n```mojo title=\"tiled_matmul.mojo\"\nfrom math import ceildiv\nfrom sys import exit, has_accelerator", "position": 14, "token_count": 244, "has_code": true, "section_hierarchy": ["Block synchronization example: tiled matrix multiplication"], "metadata": {"chunk_id": "gpu-block-and-warp-014", "document_id": "gpu-block-and-warp", "position": 14, "token_count": 244, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Block synchronization example: tiled matrix multiplication"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#block-synchronization-example-tiled-matrix-multiplication"}}
{"chunk_id": "gpu-block-and-warp-015", "document_id": "gpu-block-and-warp", "content": "# GPU programming imports from open source stdlib\nfrom gpu.sync import barrier\nfrom gpu.host import DeviceContext\nfrom gpu import thread_idx, block_idx\nfrom gpu.memory import AddressSpace\n\n# Layout tensor support from open source layout package\nfrom layout import Layout, LayoutTensor\n\n# Data type selection: float32 provides good balance of precision and performance\nalias float_dtype = DType.float32\n\n# Matrix dimensions: chosen to be small enough for easy understanding\n# while still demonstrating tiling concepts effectively\nalias MATRIX_SIZE = 64 # 64x64 matrices\nalias MATRIX_M = MATRIX_SIZE # Number of rows in matrices A and C\nalias MATRIX_N = MATRIX_SIZE # Number of columns in matrices B and C\nalias MATRIX_K = MATRIX_SIZE # Shared dimension (A cols = B rows)\n\n# Tile dimensions: chosen to fit comfortably in GPU shared memory", "position": 15, "token_count": 189, "has_code": false, "section_hierarchy": ["Tile dimensions: chosen to fit comfortably in GPU shared memory"], "metadata": {"chunk_id": "gpu-block-and-warp-015", "document_id": "gpu-block-and-warp", "position": 15, "token_count": 189, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Tile dimensions: chosen to fit comfortably in GPU shared memory"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#tile-dimensions-chosen-to-fit-comfortably-in-gpu-shared-memory"}}
{"chunk_id": "gpu-block-and-warp-016", "document_id": "gpu-block-and-warp", "content": "# Tile dimensions: chosen to fit comfortably in GPU shared memory\n# and demonstrate clear blocking behavior\nalias TILE_SIZE = 16 # 16x16 tiles balance memory usage and parallelism\nalias TILE_M = TILE_SIZE # Tile height for matrix A and C\nalias TILE_N = TILE_SIZE # Tile width for matrix B and C\nalias TILE_K = TILE_SIZE # Tile depth for the K dimension\n\n# Derived constants\nalias NUM_TILES_PER_SIDE = MATRIX_SIZE // TILE_SIZE # Number of tiles per matrix side (4)\nalias THREADS_PER_TILE = TILE_SIZE * TILE_SIZE # Threads needed per tile (256)\nalias TOTAL_TILES_TO_PROCESS = NUM_TILES_PER_SIDE # Tiles to process in K dimension\n\n# LayoutTensor provides type-safe multi-dimensional data access with automatic memory layout handling", "position": 16, "token_count": 181, "has_code": false, "section_hierarchy": ["LayoutTensor provides type-safe multi-dimensional data access with automatic memory layout handling"], "metadata": {"chunk_id": "gpu-block-and-warp-016", "document_id": "gpu-block-and-warp", "position": 16, "token_count": 181, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["LayoutTensor provides type-safe multi-dimensional data access with automatic memory layout handling"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#layouttensor-provides-type-safe-multi-dimensional-data-access-with-automatic-memory-layout-handling"}}
{"chunk_id": "gpu-block-and-warp-017", "document_id": "gpu-block-and-warp", "content": "# LayoutTensor provides type-safe multi-dimensional data access with automatic memory layout handling\n# Layout definitions using example matrix dimensions\nalias matrix_a_layout = Layout.row_major(MATRIX_M, MATRIX_K) # A: M x K\nalias matrix_b_layout = Layout.row_major(MATRIX_K, MATRIX_N) # B: K x N\nalias matrix_c_layout = Layout.row_major(MATRIX_M, MATRIX_N) # C: M x N", "position": 17, "token_count": 108, "has_code": false, "section_hierarchy": ["Layout definitions using example matrix dimensions"], "metadata": {"chunk_id": "gpu-block-and-warp-017", "document_id": "gpu-block-and-warp", "position": 17, "token_count": 108, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Layout definitions using example matrix dimensions"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#layout-definitions-using-example-matrix-dimensions"}}
{"chunk_id": "gpu-block-and-warp-018", "document_id": "gpu-block-and-warp", "content": "# Layout definitions for tile access\nalias tile_a_layout = Layout.row_major(TILE_M, TILE_K)\nalias tile_b_layout = Layout.row_major(TILE_K, TILE_N)\n\nfn tiled_matmul_kernel(\n matrix_a: LayoutTensor[float_dtype, matrix_a_layout, MutAnyOrigin],\n matrix_b: LayoutTensor[float_dtype, matrix_b_layout, MutAnyOrigin],\n matrix_c: LayoutTensor[float_dtype, matrix_c_layout, MutAnyOrigin],\n):\n # Thread and block indices\n var thread_x = thread_idx.x\n var thread_y = thread_idx.y\n var block_x = block_idx.x\n var block_y = block_idx.y\n\n # Global matrix coordinates\n var global_row = block_y * TILE_M + thread_y\n var global_col = block_x * TILE_N + thread_x", "position": 18, "token_count": 225, "has_code": false, "section_hierarchy": ["Layout definitions for tile access"], "metadata": {"chunk_id": "gpu-block-and-warp-018", "document_id": "gpu-block-and-warp", "position": 18, "token_count": 225, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Layout definitions for tile access"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#layout-definitions-for-tile-access"}}
{"chunk_id": "gpu-block-and-warp-019", "document_id": "gpu-block-and-warp", "content": "# Global matrix coordinates\n var global_row = block_y * TILE_M + thread_y\n var global_col = block_x * TILE_N + thread_x\n\n # Tile starting positions\n var tile_row_start = block_y * TILE_M\n var tile_col_start = block_x * TILE_N\n\n # Allocate shared memory tiles for fast on-chip access\n var tile_a_shared = LayoutTensor[\n float_dtype,\n tile_a_layout,\n MutAnyOrigin,\n address_space = AddressSpace.SHARED,\n ].stack_allocation()\n\n var tile_b_shared = LayoutTensor[\n float_dtype,\n tile_b_layout,\n MutAnyOrigin,\n address_space = AddressSpace.SHARED,\n ].stack_allocation()\n\n # Initialize accumulator and start tiling loop\n var accumulator: matrix_c.element_type = 0.0", "position": 19, "token_count": 198, "has_code": false, "section_hierarchy": ["Global matrix coordinates"], "metadata": {"chunk_id": "gpu-block-and-warp-019", "document_id": "gpu-block-and-warp", "position": 19, "token_count": 198, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Global matrix coordinates"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#global-matrix-coordinates"}}
{"chunk_id": "gpu-block-and-warp-020", "document_id": "gpu-block-and-warp", "content": "# Initialize accumulator and start tiling loop\n var accumulator: matrix_c.element_type = 0.0\n\n # Iterate through tiles along K dimension\n # Use @parameter to unroll the loop at compile time\n @parameter\n for k_tile in range(0, MATRIX_K, TILE_K):\n # Cooperative tile loading\n # Calculate global coordinates for tile loading\n var a_global_row = tile_row_start + thread_y\n var a_global_col = UInt(k_tile) + thread_x\n var b_global_row = UInt(k_tile) + thread_y\n var b_global_col = tile_col_start + thread_x\n\n # Bounds checking\n var load_a_valid = (a_global_row < MATRIX_M) and (\n a_global_col < MATRIX_K\n )\n var load_b_valid = (b_global_row < MATRIX_K) and (\n b_global_col < MATRIX_N\n )", "position": 20, "token_count": 212, "has_code": false, "section_hierarchy": ["Initialize accumulator and start tiling loop"], "metadata": {"chunk_id": "gpu-block-and-warp-020", "document_id": "gpu-block-and-warp", "position": 20, "token_count": 212, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Initialize accumulator and start tiling loop"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#initialize-accumulator-and-start-tiling-loop"}}
{"chunk_id": "gpu-block-and-warp-021", "document_id": "gpu-block-and-warp", "content": "# Load tiles into shared memory with bounds checking\n if load_a_valid:\n tile_a_shared[thread_y, thread_x] = matrix_a[\n a_global_row, a_global_col\n ]\n else:\n tile_a_shared[thread_y, thread_x] = 0.0\n\n if load_b_valid:\n tile_b_shared[thread_y, thread_x] = matrix_b[\n b_global_row, b_global_col\n ]\n else:\n tile_b_shared[thread_y, thread_x] = 0.0\n\n # Ensure all threads finish loading tiles before any thread starts computing\n barrier()\n\n # Compute dot product using shared memory tiles\n @parameter\n for k in range(TILE_K):\n var a_element = tile_a_shared[thread_y, k]\n var b_element = tile_b_shared[k, thread_x]\n accumulator += a_element * b_element\n\n # Ensure all threads finish computing before any thread loads next tiles\n barrier()", "position": 21, "token_count": 223, "has_code": false, "section_hierarchy": ["Load tiles into shared memory with bounds checking"], "metadata": {"chunk_id": "gpu-block-and-warp-021", "document_id": "gpu-block-and-warp", "position": 21, "token_count": 223, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Load tiles into shared memory with bounds checking"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#load-tiles-into-shared-memory-with-bounds-checking"}}
{"chunk_id": "gpu-block-and-warp-022", "document_id": "gpu-block-and-warp", "content": "# Ensure all threads finish computing before any thread loads next tiles\n barrier()\n\n # Write final result to global memory with bounds checking\n if (global_row < MATRIX_M) and (global_col < MATRIX_N):\n matrix_c[global_row, global_col] = accumulator", "position": 22, "token_count": 64, "has_code": false, "section_hierarchy": ["Ensure all threads finish computing before any thread loads next tiles"], "metadata": {"chunk_id": "gpu-block-and-warp-022", "document_id": "gpu-block-and-warp", "position": 22, "token_count": 64, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Ensure all threads finish computing before any thread loads next tiles"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#ensure-all-threads-finish-computing-before-any-thread-loads-next-tiles"}}
{"chunk_id": "gpu-block-and-warp-023", "document_id": "gpu-block-and-warp", "content": "```\n\nThis tiled algorithm leverages the GPU's memory hierarchy for better\nperformance. Shared memory is an on-chip cache that's much faster than global\nmemory, but it's limited in size—a typical block might have only 48KB available.\nWe break the computation into stages: threads cooperatively load small tiles\nfrom global memory into this fast shared memory, perform computations on those\ntiles, then repeat for the next set of tiles. Each thread loads one element per\ntile, creating coalesced memory accesses that maximize bandwidth. Once a tile\nsits in shared memory, all threads in the block can access it repeatedly without\ntriggering expensive global memory reads.", "position": 23, "token_count": 138, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-023", "document_id": "gpu-block-and-warp", "position": 23, "token_count": 138, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-024", "document_id": "gpu-block-and-warp", "content": "The first `barrier()` call appears immediately after the cooperative tile\nloading phase. This synchronization point is critical: it ensures that all\nthreads in the block finish writing their elements to shared memory before any\nthread begins reading from it to compute results. Without this barrier, you'd\nhave a classic read-before-write race condition. Fast threads could race ahead\nand start reading from shared memory locations that slow threads haven't\npopulated yet, leading to incorrect results from uninitialized data. Even worse,\nthe bug would be non-deterministic—sometimes the code would work (if threads\nhappened to execute in a favorable order), and sometimes it would fail, making\ndebugging extremely difficult. The barrier eliminates this unpredictability by\nestablishing a clear happens-before relationship: all writes complete before any\nreads begin.", "position": 24, "token_count": 173, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-024", "document_id": "gpu-block-and-warp", "position": 24, "token_count": 173, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-025", "document_id": "gpu-block-and-warp", "content": "The second `barrier()` call appears at the end of the computation phase, right\nbefore the loop continues to load the next set of tiles. This barrier solves the\nopposite problem: it prevents write-during-read races. Without it, fast threads\ncould finish their computations and start loading new tile data into shared\nmemory while slow threads are still reading the old data for their calculations.\nThis would corrupt the shared memory with partially overwritten values, again\nproducing incorrect results. The pattern is symmetric: the first barrier\nprotects readers from seeing incomplete writes, while the second protects\nreaders from concurrent overwrites. Together, these two barriers implement a\nsafe producer-consumer cycle: load → barrier → compute → barrier → repeat. Both\nbarriers are absolutely essential—removing either one breaks the algorithm's\ncorrectness.", "position": 25, "token_count": 164, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-025", "document_id": "gpu-block-and-warp", "position": 25, "token_count": 164, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-026", "document_id": "gpu-block-and-warp", "content": "## Warp-level operations\n\nWhile the thread block is the scope for shared memory communication, the warp is\nthe fundamental unit of execution scheduling. Because threads within a warp are\nexecuted simultaneously by the hardware, communication between them happens much\nfaster than communication that requires coordination across different warps.\nMojo provides a suite of primitives for these high-speed, intra-warp operations,\nwhich are essential for many performance-critical optimization patterns.\n\nThis section covers high-speed coordination and data exchange within a single\nwarp:", "position": 26, "token_count": 102, "has_code": false, "section_hierarchy": ["Warp-level operations"], "metadata": {"chunk_id": "gpu-block-and-warp-026", "document_id": "gpu-block-and-warp", "position": 26, "token_count": 102, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Warp-level operations"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#warp-level-operations"}}
{"chunk_id": "gpu-block-and-warp-027", "document_id": "gpu-block-and-warp", "content": "This section covers high-speed coordination and data exchange within a single\nwarp:\n\n- [Warp-level synchronization](#warp-level-synchronization): How to use\n `syncwarp()` for fine-grained synchronization within a warp, and when it's\n needed vs. when it's not.\n- [Warp-level data exchange](#warp-level-data-exchange): Register-to-register\n communication with shuffle operations (`shuffle_up`, `shuffle_down`,\n `shuffle_xor`, `shuffle_idx`, `broadcast`).\n- [Warp-level reduction operations](#warp-level-reduction-operations):\n High-performance collective operations (`sum`, `max`, `min`, `prefix_sum`)\n that operate only within a warp.", "position": 27, "token_count": 186, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-027", "document_id": "gpu-block-and-warp", "position": 27, "token_count": 186, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-028", "document_id": "gpu-block-and-warp", "content": "### Warp-level synchronization\n\nThe [`gpu.sync.syncwarp()`](/mojo/stdlib/gpu/sync/sync/syncwarp) function\nprovides a more granular synchronization barrier that operates only on the\nthreads within a single warp.\n\nThis function handles *thread divergence*. On some GPU architectures, threads\nwithin a warp can follow different execution paths due to conditional branching.\n`syncwarp()` forces the specified threads in the warp to reconverge at a single\npoint before proceeding.\n\n[tip]\nFor coordinating threads across multiple warps within a thread block, use\n[`barrier()`](#the-barrier-primitive) instead, which synchronizes all threads in\nthe block and provides memory fence guarantees for shared memory access.", "position": 28, "token_count": 177, "has_code": false, "section_hierarchy": ["Warp-level synchronization"], "metadata": {"chunk_id": "gpu-block-and-warp-028", "document_id": "gpu-block-and-warp", "position": 28, "token_count": 177, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Warp-level synchronization"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#warp-level-synchronization"}}
{"chunk_id": "gpu-block-and-warp-029", "document_id": "gpu-block-and-warp", "content": "The `syncwarp()` function takes an optional `mask` argument. This is a 32-bit or\n64-bit integer (depending on the warp size of the architecture) that acts as a\nbitmask. The `i`th bit of the mask corresponds to the thread at lane `i` within\nthe warp. If a bit is set to 1, the corresponding thread participates in the\nsynchronization; if it is 0, it does not. The default value of -1 (all bits set\nto 1) synchronizes all threads in the warp.\n\nUnderstanding `syncwarp()` requires knowing its platform-dependent behavior,\nwhich Mojo's portable API abstracts away:\n\n- On NVIDIA GPUs supporting independent thread scheduling (Volta architecture\n and newer), threads within a warp can genuinely diverge. In this context,\n `syncwarp()` compiles to an active hardware instruction (`bar.warp.sync`) that\n forces the participating threads to wait for each other. It is necessary for\n correctness in algorithms that rely on warp-synchronous behavior.", "position": 29, "token_count": 231, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-029", "document_id": "gpu-block-and-warp", "position": 29, "token_count": 231, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-030", "document_id": "gpu-block-and-warp", "content": "- On AMD GPUs, threads within a wavefront (the AMD equivalent of a warp) are\n guaranteed by the hardware to execute in lock-step. They cannot diverge in the\n same way. Consequently, `syncwarp()` is a **no-op** on AMD architectures; the\n Mojo compiler emits no instruction for it.\n\n- On Apple silicon GPUs, this provides only execution synchronization within a\n SIMD group (the Apple equivalent of a warp), with no memory fence (the Apple\n Metal equivalent of `simdgroup_barrier(mem_flags::mem_none)`). Lane masks are\n not supported, so the `mask` argument is ignored and all active lanes must\n reach this point.\n\nThis difference highlights a key benefit of Mojo. You write code against a\nsingle, portable API. The compiler is responsible for generating the correct,\narchitecture-specific code. Therefore, if an algorithm relies on `syncwarp()`\nfor correctness on NVIDIA hardware, it still behaves as expected on other\nvendors' hardware.", "position": 30, "token_count": 229, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-030", "document_id": "gpu-block-and-warp", "position": 30, "token_count": 229, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-031", "document_id": "gpu-block-and-warp", "content": "[note]\n[Warp shuffle operations](#warp-level-data-exchange) (like `shuffle_down()`,\n`shuffle_xor()`, etc.) and\n[warp reduction operations](#warp-level-reduction-operations) (like `max()`,\n`prefix_sum()`, `sum()`, etc.) provide **implicit synchronization** and do\n**not** require `syncwarp()` calls before them. Calling `syncwarp()` before a\nwarp shuffle or reduction operation is redundant and unnecessary.", "position": 31, "token_count": 132, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-031", "document_id": "gpu-block-and-warp", "position": 31, "token_count": 132, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-032", "document_id": "gpu-block-and-warp", "content": "### Warp-level data exchange\n\nShuffle operations are the cornerstone of high-performance warp-level\nalgorithms. These primitives enable threads within a warp to exchange data\ndirectly through registers, making them essential for implementing efficient\nparallel patterns like reductions, stencil computations, and sliding window\noperations.\n\nUnlike shared memory communication that requires explicit synchronization and\nmemory transactions, shuffle operations use the warp's simultaneous execution\nto achieve near-zero latency data exchange. This makes them ideal for:\n\n- Neighbor data access: Access elements from adjacent threads in stencil\n operations or convolutions.\n- Tree-structured reductions: Implement butterfly patterns for parallel\n reductions and prefix operations.\n- Data broadcasting: Distribute computed values or constants across all threads\n in a warp.\n- Sliding window algorithms: Efficiently compute running maximums, minimums, or\n moving averages.", "position": 32, "token_count": 173, "has_code": false, "section_hierarchy": ["Warp-level data exchange"], "metadata": {"chunk_id": "gpu-block-and-warp-032", "document_id": "gpu-block-and-warp", "position": 32, "token_count": 173, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Warp-level data exchange"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#warp-level-data-exchange"}}
{"chunk_id": "gpu-block-and-warp-033", "document_id": "gpu-block-and-warp", "content": "#### Warp shuffle operations\n\nThe [`gpu.primitives.warp`](/mojo/stdlib/gpu/primitives/warp) module provides\nfive shuffle primitives, each optimized for specific data movement patterns:\n\n- [`shuffle_up(value, delta)`](/mojo/stdlib/gpu/primitives/warp/shuffle_up):\n Each thread receives the value from a thread with a lower lane ID (that is,\n from lane current_lane - `delta`). If the resulting lane ID is less than 0,\n the thread receives an undefined value.\n\n- [`shuffle_down(value, delta)`](/mojo/stdlib/gpu/primitives/warp/shuffle_down):\n Each thread receives a value from a thread with a higher lane ID (that is,\n from lane current_lane + `delta`). If the resulting lane ID is greater than or\n equal to the warp size, the thread receives an undefined value.", "position": 33, "token_count": 219, "has_code": false, "section_hierarchy": ["Warp shuffle operations"], "metadata": {"chunk_id": "gpu-block-and-warp-033", "document_id": "gpu-block-and-warp", "position": 33, "token_count": 219, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Warp shuffle operations"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#warp-shuffle-operations"}}
{"chunk_id": "gpu-block-and-warp-034", "document_id": "gpu-block-and-warp", "content": "- [`shuffle_xor(value, offset)`](/mojo/stdlib/gpu/primitives/warp/shuffle_xor):\n Each thread exchanges its value with the thread at lane current_lane XOR\n `offset`. This is particularly useful for implementing butterfly patterns\n common in algorithms like FFTs and parallel reductions.\n\n- [`shuffle_idx(value, src_lane)`](/mojo/stdlib/gpu/primitives/warp/shuffle_idx):\n Each thread receives the value from the thread at the specified `src_lane`.\n This is effectively a broadcast from one lane to all others in the warp.\n Essential for sharing computed results or constants across the entire warp.\n\n- [`broadcast(value)`](/mojo/stdlib/gpu/primitives/warp/broadcast): A\n convenience wrapper around `shuffle_idx()` that distributes the value from\n lane 0 to all other threads in the warp.\n\nAll of these primitives other than `broadcast()` take an optional `mask`\nargument that serves a dual purpose:", "position": 34, "token_count": 242, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-034", "document_id": "gpu-block-and-warp", "position": 34, "token_count": 242, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-035", "document_id": "gpu-block-and-warp", "content": "All of these primitives other than `broadcast()` take an optional `mask`\nargument that serves a dual purpose:\n\n1. **Thread participation**: The mask specifies which threads participate in the\n shuffle operation. It is a 32-bit or 64-bit integer (depending on the warp\n size) where the `i`th bit corresponds to lane `i`. If a bit is set to 1, that\n thread participates; if 0, it does not.\n\n2. **Implicit synchronization**: The mask also provides automatic\n synchronization for all participating threads. All threads whose bits are set\n in the mask will be synchronized before the shuffle completes, ensuring\n correct data exchange even after divergent control flow.\n\nThe default value of -1 (all bits set to 1) includes all threads in the warp.\n\ncaution Warning", "position": 35, "token_count": 174, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-035", "document_id": "gpu-block-and-warp", "position": 35, "token_count": 174, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-036", "document_id": "gpu-block-and-warp", "content": "The default value of -1 (all bits set to 1) includes all threads in the warp.\n\ncaution Warning\n\nWhen using a full mask (all bits set) in divergent code, **all threads in the\nwarp must eventually reach the shuffle instruction**, even if some threads don't\nactively use the result. If some threads take a path that never reaches the\nshuffle, those threads will never arrive at the synchronization point, causing\nthe other threads to hang indefinitely waiting for them.\n\nThese five primitives form the foundation for complex warp-level algorithms and\nserve as building blocks for higher-level collective operations.", "position": 36, "token_count": 128, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-036", "document_id": "gpu-block-and-warp", "position": 36, "token_count": 128, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-037", "document_id": "gpu-block-and-warp", "content": "#### Choosing the right shuffle primitive\n\nWhile each shuffle primitive can technically perform any data exchange pattern,\ncertain operations naturally fit specific use cases. Understanding these\npatterns helps you write more efficient and readable code.\n\n- If you need to share one thread's data with everyone else, reach for\n `broadcast()` when the source is lane 0, or `shuffle_idx()` for any other\n lane. Think of distributing a loop bound that one thread computed, or sharing\n a decision that a \"leader\" thread made.\n\n- For algorithms that process neighboring data—like stencil operations or\n convolutions—`shuffle_up()` and `shuffle_down()` are your best bet. These let\n you grab values from adjacent threads without the coordination overhead of\n shared memory. A sliding window average becomes as simple as adding your\n neighbors' values to your own.\n\n- When implementing tree-structured algorithms like parallel reductions,\n `shuffle_xor()` shines. Its butterfly communication pattern naturally maps to\n how these algorithms exchange data. Most high-performance reduction\n implementations use `shuffle_xor()` because it has excellent instruction\n scheduling properties.", "position": 37, "token_count": 240, "has_code": false, "section_hierarchy": ["Choosing the right shuffle primitive"], "metadata": {"chunk_id": "gpu-block-and-warp-037", "document_id": "gpu-block-and-warp", "position": 37, "token_count": 240, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Choosing the right shuffle primitive"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#choosing-the-right-shuffle-primitive"}}
{"chunk_id": "gpu-block-and-warp-038", "document_id": "gpu-block-and-warp", "content": "Here are some specific patterns where each primitive excels.\n\n`shuffle_idx()` and `broadcast()` work well for:\n- Distributing computed constants or array bounds\n- Implementing voting mechanisms across the warp\n- Sharing results from a designated \"leader\" thread\n\n`shuffle_up()` and `shuffle_down()` are perfect for:\n- Stencil computations that need neighboring grid points\n- Finite difference schemes requiring adjacent values\n- Any sliding window algorithm (moving averages, local extrema)\n\n`shuffle_xor()` excels at:\n- Parallel reductions using butterfly patterns\n- Any computation with power-of-2 communication strides\n\nWhen optimizing performance, prefer shuffle operations over shared memory for\nregister-sized data, and remember that `shuffle_xor()` typically has the best\ninstruction scheduling characteristics for reduction patterns.", "position": 38, "token_count": 176, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-038", "document_id": "gpu-block-and-warp", "position": 38, "token_count": 176, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-039", "document_id": "gpu-block-and-warp", "content": "### Warp-level reduction operations\n\nThe `gpu.primitives.warp` module also provides higher-level functions for\nperforming common reduction computations across all threads in a warp. These\nfunctions take advantage of hardware-specific intrinsics where possible, and\nfall back to shuffle-based reduction on other architectures:\n\n- [`max(value)`](/mojo/stdlib/gpu/primitives/warp/max): Computes the maximum\n `value` across all threads in the warp. The result is broadcast to all lanes.\n\n- [`min(value)`](/mojo/stdlib/gpu/primitives/warp/min): Computes the minimum\n `value` across all threads in the warp. The result is broadcast to all lanes.\n\n- [`sum(value)`](/mojo/stdlib/gpu/primitives/warp/sum): Computes the sum of\n `value` across all threads in the warp. The result is broadcast to all lanes.", "position": 39, "token_count": 217, "has_code": false, "section_hierarchy": ["Warp-level reduction operations"], "metadata": {"chunk_id": "gpu-block-and-warp-039", "document_id": "gpu-block-and-warp", "position": 39, "token_count": 217, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Warp-level reduction operations"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#warp-level-reduction-operations"}}
{"chunk_id": "gpu-block-and-warp-040", "document_id": "gpu-block-and-warp", "content": "- [`prefix_sum[exclusive=False](value)`](/mojo/stdlib/gpu/primitives/warp/prefix_sum):\n Computes an inclusive (default) or exclusive prefix sum (scan) across threads\n in the warp. A prefix sum transforms an input sequence into cumulative sums:\n given $[x_0, x_1, x_2, x_3]$, an *inclusive* scan produces $[x_0, x_0+x_1,\n x_0+x_1+x_2, x_0+x_1+x_2+x_3]$ where each thread receives the sum of all\n values up to and including its own, while an *exclusive* scan produces $[0,\n x_0, x_0+x_1, x_0+x_1+x_2]$ where each thread receives the sum of all values\n *before* it.", "position": 40, "token_count": 206, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-040", "document_id": "gpu-block-and-warp", "position": 40, "token_count": 206, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-041", "document_id": "gpu-block-and-warp", "content": "You'll find these primitives most useful when computing aggregates across\nthreads that are already working closely together. Use `sum()` for computing\ntotals, averages, or accumulating values across small data segments. The `max()`\nand `min()` functions work well for finding extremes in your data or\nimplementing voting mechanisms where threads need consensus. `prefix_sum()` is\nparticularly valuable for *scan* operations—computing running totals or building\ncumulative results as you process data. It's essential for algorithms that need\nto track \"how much have we processed so far?\" at each step. These operations are\nsignificantly faster than a block-level reduction that uses shared memory and\n`barrier()` calls.", "position": 41, "token_count": 151, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-041", "document_id": "gpu-block-and-warp", "position": 41, "token_count": 151, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-042", "document_id": "gpu-block-and-warp", "content": "### Using warp operations in practice\n\nWarp operations excel in algorithms that require frequent, fine-grained data\nexchange between nearby threads. Common patterns include:\n\n- Sliding window operations: Use `shuffle_up()` and `shuffle_down()` to\n access neighboring lane values.\n\n- Butterfly reductions: Use `shuffle_xor()` for efficient tree-like\n reduction patterns that minimize the number of shuffle steps.\n\n- Broadcasting computed values: Use `broadcast()` to share a single thread's\n computation result (like a loop bound or pointer) across the entire warp.\n\nThese operations are particularly valuable in algorithms where the overhead of\nblock-level synchronization would be prohibitive, such as in inner loops of\ncompute-intensive kernels or when processing data that naturally aligns with\nwarp boundaries.", "position": 42, "token_count": 167, "has_code": false, "section_hierarchy": ["Using warp operations in practice"], "metadata": {"chunk_id": "gpu-block-and-warp-042", "document_id": "gpu-block-and-warp", "position": 42, "token_count": 167, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Using warp operations in practice"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#using-warp-operations-in-practice"}}
{"chunk_id": "gpu-block-and-warp-043", "document_id": "gpu-block-and-warp", "content": "## Advanced synchronization mechanisms\n\nBeyond the fundamental `barrier()` and `syncwarp()` primitives, Mojo provides\nadditional synchronization mechanisms for specialized use cases and\narchitecture-specific optimizations. These advanced primitives enable\nfine-grained control over memory ordering, asynchronous operations, and\ninstruction scheduling. However, most of these mechanisms are available only on\nspecific architectures. Consult the Mojo API reference documentation for the\nlatest information on availability.\n\nMechanisms currently available only on NVIDIA GPUs:", "position": 43, "token_count": 111, "has_code": false, "section_hierarchy": ["Advanced synchronization mechanisms"], "metadata": {"chunk_id": "gpu-block-and-warp-043", "document_id": "gpu-block-and-warp", "position": 43, "token_count": 111, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Advanced synchronization mechanisms"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#advanced-synchronization-mechanisms"}}
{"chunk_id": "gpu-block-and-warp-044", "document_id": "gpu-block-and-warp", "content": "- **Semaphores**\n ([`gpu.sync.semaphore.Semaphore`](/mojo/stdlib/gpu/sync/semaphore/Semaphore),\n [`gpu.sync.semaphore.NamedBarrierSemaphore`](/mojo/stdlib/gpu/sync/semaphore/NamedBarrierSemaphore)):\n Device-wide semaphore implementations for inter-CTA synchronization using\n shared lock variables. Provides\n [`fetch()`](/mojo/stdlib/gpu/sync/semaphore/Semaphore/#fetch),\n [`wait()`](/mojo/stdlib/gpu/sync/semaphore/Semaphore/#wait),", "position": 44, "token_count": 194, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-044", "document_id": "gpu-block-and-warp", "position": 44, "token_count": 194, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-045", "document_id": "gpu-block-and-warp", "content": "[`wait()`](/mojo/stdlib/gpu/sync/semaphore/Semaphore/#wait),\n [`release()`](/mojo/stdlib/gpu/sync/semaphore/Semaphore/#release), and\n [`state()`](/mojo/stdlib/gpu/sync/semaphore/Semaphore/#state) methods for\n state management methods for coordinating work across thread blocks.", "position": 45, "token_count": 116, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-045", "document_id": "gpu-block-and-warp", "position": 45, "token_count": 116, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-046", "document_id": "gpu-block-and-warp", "content": "- **Named barriers**\n ([`gpu.sync.named_barrier()`](/mojo/stdlib/gpu/sync/sync/named_barrier),\n [`gpu.sync.named_barrier_arrive()`](/mojo/stdlib/gpu/sync/sync/named_barrier_arrive)):\n Hardware-accelerated block-level barriers using barrier IDs (0-16) for\n split-phase synchronization patterns. Useful for TMA operations and high-performance\n pipeline algorithms.", "position": 46, "token_count": 121, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-046", "document_id": "gpu-block-and-warp", "position": 46, "token_count": 121, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-047", "document_id": "gpu-block-and-warp", "content": "- **Memory barriers**:\n A suite of functions for tracking asynchronous memory operations and\n coordinating phased synchronization in shared memory. Includes\n [`gpu.sync.mbarrier_init()`](/mojo/stdlib/gpu/sync/sync/mbarrier_init),\n ([`gpu.sync.mbarrier_arrive()`](/mojo/stdlib/gpu/sync/sync/mbarrier_arrive),\n [`gpu.sync.mbarrier_arrive_expect_tx_shared()`](/mojo/stdlib/gpu/sync/sync/mbarrier_arrive_expect_tx_shared),\n [`gpu.sync.mbarrier_arrive_expect_tx_relaxed()`](/mojo/stdlib/gpu/sync/sync/mbarrier_arrive_expect_tx_relaxed),", "position": 47, "token_count": 206, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-047", "document_id": "gpu-block-and-warp", "position": 47, "token_count": 206, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-048", "document_id": "gpu-block-and-warp", "content": "[`gpu.sync.mbarrier_arrive_expect_tx_relaxed()`](/mojo/stdlib/gpu/sync/sync/mbarrier_arrive_expect_tx_relaxed),\n [`gpu.sync.mbarrier_test_wait()`](/mojo/stdlib/gpu/sync/sync/mbarrier_test_wait),\n and\n [`gpu.sync.mbarrier_try_wait_parity_shared()`](/mojo/stdlib/gpu/sync/sync/mbarrier_try_wait_parity_shared)).", "position": 48, "token_count": 142, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-048", "document_id": "gpu-block-and-warp", "position": 48, "token_count": 142, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-049", "document_id": "gpu-block-and-warp", "content": "- **Thread fence**\n ([`gpu.intrinsics.threadfence()`](/mojo/stdlib/gpu/intrinsics/threadfence)):\n Memory ordering fence (no execution barrier) that ensures memory operations\n are visible within a specified scope (block, GPU-wide, or system). Essential\n for lock-free algorithms and cross-block communication.\n\n- **Async bulk copy synchronization**\n ([`gpu.sync.cp_async_bulk_commit_group()`](/mojo/stdlib/gpu/sync/sync/cp_async_bulk_commit_group),\n [`gpu.sync.cp_async_bulk_wait_group()`](/mojo/stdlib/gpu/sync/sync/cp_async_bulk_wait_group)):\n Functions for coordinating asynchronous bulk memory transfer groups. Essential\n for managing pipeline stages with bulk memory operations.\n\nMechanisms currently available only on AMD GPUs:", "position": 49, "token_count": 236, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-049", "document_id": "gpu-block-and-warp", "position": 49, "token_count": 236, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-050", "document_id": "gpu-block-and-warp", "content": "Mechanisms currently available only on AMD GPUs:\n\n- **Schedule barriers**\n ([`gpu.sync.schedule_barrier()`](/mojo/stdlib/gpu/sync/sync/schedule_barrier),\n [`gpu.sync.schedule_group_barrier()`](/mojo/stdlib/gpu/sync/sync/schedule_group_barrier)):\n Compiler instruction scheduling controls that allow selective reordering of\n instruction types across barriers. Enables performance optimizations by\n controlling which instruction categories can cross the barrier.", "position": 50, "token_count": 123, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-050", "document_id": "gpu-block-and-warp", "position": 50, "token_count": 123, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-051", "document_id": "gpu-block-and-warp", "content": "- **Wait count**\n ([`gpu.sync.s_waitcnt()`](/mojo/stdlib/gpu/sync/sync/s_waitcnt),\n [`gpu.sync.s_waitcnt_barrier()`](/mojo/stdlib/gpu/sync/sync/s_waitcnt_barrier)):\n Precise synchronization primitives that wait for outstanding memory operations\n to complete based on counter values (vector memory, export, and LGKM\n counters). Available on **AMD CDNA GPUs only** (not available on older AMD\n architectures).", "position": 51, "token_count": 147, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-051", "document_id": "gpu-block-and-warp", "position": 51, "token_count": 147, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-052", "document_id": "gpu-block-and-warp", "content": "## Best practices and common pitfalls\n\nNow that we've covered the core synchronization primitives, let's focus on using\nthem correctly to write reliable and portable GPU code. Understanding common\npitfalls is essential for avoiding bugs that are difficult to reproduce and\ndebug.\n\nThis section provides guidance for writing correct, portable, and efficient GPU\ncode:\n\n- [Writing correct synchronized code](#writing-correct-synchronized-code):\n Avoiding race conditions, deadlocks, and understanding when to use\n `syncwarp()` vs. when shuffle operations handle synchronization automatically.\n- [Choosing the right synchronization level](#choosing-the-right-synchronization-level):\n When to use warp-level operations vs. block-level synchronization.\n- [Writing portable GPU code](#writing-portable-gpu-code): Using Mojo's\n abstractions to write code that works across NVIDIA, AMD, and Apple hardware.", "position": 52, "token_count": 214, "has_code": false, "section_hierarchy": ["Best practices and common pitfalls"], "metadata": {"chunk_id": "gpu-block-and-warp-052", "document_id": "gpu-block-and-warp", "position": 52, "token_count": 214, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Best practices and common pitfalls"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#best-practices-and-common-pitfalls"}}
{"chunk_id": "gpu-block-and-warp-053", "document_id": "gpu-block-and-warp", "content": "### Writing correct synchronized code\n\nCorrectness should always be your first priority. The following issues are\ncommon sources of bugs in parallel programs.\n\n#### Understanding and avoiding race conditions\n\nAs a quick reminder, a race condition occurs when multiple threads write to the\nsame memory location without a defined order of execution, leading to a\nnon-deterministic outcome. Here's a simple example where threads attempt to\nupdate a shared counter:\n\n```mojo", "position": 53, "token_count": 93, "has_code": true, "section_hierarchy": ["Understanding and avoiding race conditions"], "metadata": {"chunk_id": "gpu-block-and-warp-053", "document_id": "gpu-block-and-warp", "position": 53, "token_count": 93, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Understanding and avoiding race conditions"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#understanding-and-avoiding-race-conditions"}}
{"chunk_id": "gpu-block-and-warp-054", "document_id": "gpu-block-and-warp", "content": "# INCORRECT: Race condition\nshared_counter[0] += my_value # Multiple threads modify same location\n```\n\nThis leads to \"lost updates\" because the read-modify-write sequence isn't\natomic. To prevent this, you must use synchronization primitives like\n`barrier()` to coordinate access or use\n[`Atomic`](/mojo/stdlib/os/atomic/Atomic/) operations for simple updates. For\nexample, you could use the\n[`Atomic.fetch_add()`](/mojo/stdlib/os/atomic/Atomic/#fetch_add) method to\natomically increment the counter:\n\n```mojo", "position": 54, "token_count": 147, "has_code": true, "section_hierarchy": ["INCORRECT: Race condition"], "metadata": {"chunk_id": "gpu-block-and-warp-054", "document_id": "gpu-block-and-warp", "position": 54, "token_count": 147, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["INCORRECT: Race condition"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#incorrect-race-condition"}}
{"chunk_id": "gpu-block-and-warp-055", "document_id": "gpu-block-and-warp", "content": "# CORRECT: Atomic increment\n_ = Atomic.fetch_add(shared_counter[0], my_value)\n```\n\n#### Avoiding deadlocks with `barrier()`\n\nA `barrier()` must be encountered by all threads within a block to avoid a\ndeadlock. Placing a `barrier()` inside a conditional statement is a frequent\nsource of bugs. If the condition causes some threads to execute the `barrier()`\nwhile others skip it, the threads that reach the barrier will wait indefinitely\nfor the others to arrive, causing the kernel to hang.\n\nTherefore, `barrier()` should be used in conditional code only if it's\nguaranteed that all threads in the block will evaluate the condition identically\nand follow the same execution path.", "position": 55, "token_count": 162, "has_code": true, "section_hierarchy": ["Avoiding deadlocks with `barrier()`"], "metadata": {"chunk_id": "gpu-block-and-warp-055", "document_id": "gpu-block-and-warp", "position": 55, "token_count": 162, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Avoiding deadlocks with `barrier()`"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#avoiding-deadlocks-with-barrier"}}
{"chunk_id": "gpu-block-and-warp-056", "document_id": "gpu-block-and-warp", "content": "#### When to use `syncwarp()`\n\nThe `syncwarp()` primitive is needed when coordinating access to shared or\nglobal memory after divergent control flow within a warp. However, it is **not**\nneeded before warp shuffle operations or warp reduction operations, as those\noperations provide their own implicit synchronization via the mask parameter.\n\nUse `syncwarp()` when:\n- Threads in a warp diverge and then need to synchronize before accessing shared\n memory\n- You need to ensure all threads in a warp have completed their divergent\n execution paths before proceeding to a shared memory operation\n\nDo **not** use `syncwarp()` before:\n- Warp shuffle operations (`shuffle_down()`, `shuffle_xor()`, etc.) - these\n synchronize automatically\n- Warp reduction operations (`warp.sum()`, `warp.max()`, etc.) - these also\n synchronize automatically\n\nHere's an example where `syncwarp()` **is** needed (for shared memory\ncoordination):", "position": 56, "token_count": 239, "has_code": false, "section_hierarchy": ["When to use `syncwarp()`"], "metadata": {"chunk_id": "gpu-block-and-warp-056", "document_id": "gpu-block-and-warp", "position": 56, "token_count": 239, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["When to use `syncwarp()`"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#when-to-use-syncwarp"}}
{"chunk_id": "gpu-block-and-warp-057", "document_id": "gpu-block-and-warp", "content": "Here's an example where `syncwarp()` **is** needed (for shared memory\ncoordination):\n\n```mojo\nif thread_idx.x < 16:\n shared_data[thread_idx.x] = compute_something()\nelse:\n shared_data[thread_idx.x] = compute_something_else()", "position": 57, "token_count": 80, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-057", "document_id": "gpu-block-and-warp", "position": 57, "token_count": 80, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-058", "document_id": "gpu-block-and-warp", "content": "# syncwarp() needed here because threads diverged before writing to shared memory\nsyncwarp()\nvar result = shared_data[some_index] # Now safe to read\n```\n\nAnd here's an example where `syncwarp()` is **not** needed (shuffle operations):\n\n```mojo\nif thread_idx.x < 16:\n value = compute_something()\nelse:\n value = compute_something_else()", "position": 58, "token_count": 101, "has_code": true, "section_hierarchy": ["syncwarp() needed here because threads diverged before writing to shared memory"], "metadata": {"chunk_id": "gpu-block-and-warp-058", "document_id": "gpu-block-and-warp", "position": 58, "token_count": 101, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["syncwarp() needed here because threads diverged before writing to shared memory"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#syncwarp-needed-here-because-threads-diverged-before-writing-to-shared-memory"}}
{"chunk_id": "gpu-block-and-warp-059", "document_id": "gpu-block-and-warp", "content": "# No syncwarp() needed - shuffle_down() synchronizes automatically via its mask\nresult = warp.shuffle_down(value, 1)\n```\n\n#### Handling shuffle boundary conditions\n\nWhen using `shuffle_up()` and `shuffle_down()`, be mindful of edge cases. A\nthread will receive an undefined value if the source lane is out of bounds\n(for example, `current_lane - delta < 0`). When implementing patterns like\nsliding windows, you must add logic to handle these boundary conditions\ncorrectly.", "position": 59, "token_count": 121, "has_code": true, "section_hierarchy": ["Handling shuffle boundary conditions"], "metadata": {"chunk_id": "gpu-block-and-warp-059", "document_id": "gpu-block-and-warp", "position": 59, "token_count": 121, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Handling shuffle boundary conditions"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#handling-shuffle-boundary-conditions"}}
{"chunk_id": "gpu-block-and-warp-060", "document_id": "gpu-block-and-warp", "content": "### Choosing the right synchronization level\n\nThe core principle for designing efficient GPU algorithms is to coordinate\nbetween warps with `barrier()` and shared memory, and optimize within warps with\n`gpu.primitives.warp` primitives.\n\nThis hierarchical approach mirrors the GPU's architecture. Intra-warp\ncommunication is extremely fast, while cross-warp communication is more\nexpensive.\n\n- Use `gpu.primitives.warp` primitives for:\n - High-frequency operations inside tight loops.\n - Data exchange between neighboring threads (stencils, sliding windows).\n - Reductions or scans over small, warp-sized chunks of data.\n - Anywhere performance is latency-critical.\n\n- Use `barrier()` and `gpu.primitives.block` primitives for:\n - Coordinating access to shared memory between multiple warps.\n - Implementing multi-phase algorithms with distinct load, compute, and store\n stages.\n - Aggregating results from multiple warps within a block.", "position": 60, "token_count": 209, "has_code": false, "section_hierarchy": ["Choosing the right synchronization level"], "metadata": {"chunk_id": "gpu-block-and-warp-060", "document_id": "gpu-block-and-warp", "position": 60, "token_count": 209, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Choosing the right synchronization level"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#choosing-the-right-synchronization-level"}}
{"chunk_id": "gpu-block-and-warp-061", "document_id": "gpu-block-and-warp", "content": "### Writing portable GPU code\n\nMojo is designed to write portable GPU code, but it's helpful to understand how.\n\nFirst, Mojo's GPU operations have automatic fallback mechanisms. For example, a\n`gpu.primitives.warp.max()` call will automatically use specialized `redux`\ninstructions on the newest NVIDIA hardware but will fall back to a shuffle-based\nimplementation that works on any other GPU. You get performance where available\nand correctness everywhere else.\n\nSecond, always avoid hardcoding hardware-specific values. The most common\nmistake is assuming a warp size of 32. Use the\n[`gpu.WARP_SIZE`](/mojo/stdlib/gpu/globals/#warp_size) constant to ensure your\ncode works correctly on all vendors' hardware.\n\nFinally, for highly-tuned kernels, you can use `@parameter if` blocks to write\narchitecture-specific code paths while keeping a single source file.", "position": 61, "token_count": 206, "has_code": false, "section_hierarchy": ["Writing portable GPU code"], "metadata": {"chunk_id": "gpu-block-and-warp-061", "document_id": "gpu-block-and-warp", "position": 61, "token_count": 206, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Writing portable GPU code"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#writing-portable-gpu-code"}}
{"chunk_id": "gpu-block-and-warp-062", "document_id": "gpu-block-and-warp", "content": "Finally, for highly-tuned kernels, you can use `@parameter if` blocks to write\narchitecture-specific code paths while keeping a single source file.\n\n```mojo\nfrom sys import is_amd_gpu, is_apple_gpu, is_nvidia_gpu\n\nfn adaptive_algorithm():\n @parameter\n if is_nvidia_gpu():\n nvidia_optimized_path()\n elif is_amd_gpu():\n amd_optimized_path()\n elif is_apple_gpu():\n apple_optimized_path()\n else:\n # Conservative fallback for future hardware support\n portable_path()", "position": 62, "token_count": 155, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-062", "document_id": "gpu-block-and-warp", "position": 62, "token_count": 155, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-063", "document_id": "gpu-block-and-warp", "content": "```", "position": 63, "token_count": 5, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "gpu-block-and-warp-063", "document_id": "gpu-block-and-warp", "position": 63, "token_count": 5, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp"}}
{"chunk_id": "gpu-block-and-warp-064", "document_id": "gpu-block-and-warp", "content": "### Debugging synchronization issues\n\nSynchronization bugs can be tricky. Here are some strategies to find them:\n\n- Isolate the problem: Use simple, predictable data patterns (like each thread's\n ID) to verify your logic before using real data. Validate your parallel\n algorithm's output against a simple, sequential CPU version.\n\n- Trace execution: Add `print()` statements to trace intermediate values and\n understand how data flows through your warp-level shuffles or reduction trees.\n\n [note]\n Printing from within a kernel function is not currently supported on Apple\n silicon GPUs.\n\n\n\n- Expose scheduling-dependent bugs: Test with different thread block sizes. A\n bug that appears with one configuration but not another often points to a race\n condition.\n\n- Use dedicated tools: For complex issues, use vendor-provided GPU debugging\n tools (like the\n [NVIDIA Compute Sanitizer](https://developer.nvidia.com/compute-sanitizer))\n which can detect race conditions and memory access errors.", "position": 64, "token_count": 216, "has_code": false, "section_hierarchy": ["Debugging synchronization issues"], "metadata": {"chunk_id": "gpu-block-and-warp-064", "document_id": "gpu-block-and-warp", "position": 64, "token_count": 216, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Debugging synchronization issues"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#debugging-synchronization-issues"}}
{"chunk_id": "gpu-block-and-warp-065", "document_id": "gpu-block-and-warp", "content": "## Conclusion and key takeaways", "position": 65, "token_count": 10, "has_code": false, "section_hierarchy": ["Conclusion and key takeaways"], "metadata": {"chunk_id": "gpu-block-and-warp-065", "document_id": "gpu-block-and-warp", "position": 65, "token_count": 10, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Conclusion and key takeaways"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#conclusion-and-key-takeaways"}}
{"chunk_id": "gpu-block-and-warp-066", "document_id": "gpu-block-and-warp", "content": "### Summary of primitives and patterns\n\nWe've covered Mojo's low-level toolkit for managing concurrency and\ncommunication in GPU kernels. These primitives are the fundamental building\nblocks for writing correct and high-performance parallel algorithms.\n\n- `gpu.sync.barrier()`: The essential primitive for correctness across warps. It\n provides a block-wide synchronization point that acts as both an execution\n barrier and a memory fence, primarily to coordinate access to shared memory.\n\n- `gpu.sync.syncwarp()`: A fine-grained primitive for managing thread divergence\n within a single warp. It's necessary for correctness on hardware that supports\n independent thread scheduling.\n\n- `gpu.primitives.block` operations: High-level primitives that combine\n synchronization with common computational patterns (like reductions) across\n all threads in a block. They simplify code and are often more efficient than\n manual implementations.\n\n- `gpu.primitives.warp` primitives: The essential toolkit for performance. By\n enabling direct register-to-register communication within a warp, these\n primitives allow for extremely fast collective operations that avoid the\n higher latency of shared memory.", "position": 66, "token_count": 253, "has_code": false, "section_hierarchy": ["Summary of primitives and patterns"], "metadata": {"chunk_id": "gpu-block-and-warp-066", "document_id": "gpu-block-and-warp", "position": 66, "token_count": 253, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Summary of primitives and patterns"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#summary-of-primitives-and-patterns"}}
{"chunk_id": "gpu-block-and-warp-067", "document_id": "gpu-block-and-warp", "content": "### The core mental model\n\nThe effective use of these primitives stems from a hierarchical approach to GPU\nalgorithm design. Your key takeaway should be to coordinate between warps with\n`barrier()` and shared memory, and optimize within warps with\n`gpu.primitives.warp` primitives.\n\nThis principle encourages you to structure algorithms to maximize intra-warp\ncomputation and communication, which is extremely fast, and to use the more\ncostly block-level synchronization only when necessary to combine results or\nmanage data dependencies between warps.", "position": 67, "token_count": 117, "has_code": false, "section_hierarchy": ["The core mental model"], "metadata": {"chunk_id": "gpu-block-and-warp-067", "document_id": "gpu-block-and-warp", "position": 67, "token_count": 117, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["The core mental model"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#the-core-mental-model"}}
{"chunk_id": "gpu-block-and-warp-068", "document_id": "gpu-block-and-warp", "content": "### Next steps\n\nTo gain hands-on experience with the concepts in this guide, we encourage you\nto explore the following resources:\n\n- [Mojo GPU Puzzles](https://puzzles.modular.com/): An interactive, hands-on\n guide to mastering GPU programming patterns in Mojo, including parallel\n reductions and other algorithms that rely on these primitives.\n\n- [MAX AI Kernels Library](https://github.com/modular/modular/tree/main/max/kernels):\n For higher-level examples, the MAX AI Kernels library contains numerous\n production-grade kernels that use these low-level primitives to build highly\n optimized operations for AI and numerical computing.", "position": 68, "token_count": 151, "has_code": false, "section_hierarchy": ["Next steps"], "metadata": {"chunk_id": "gpu-block-and-warp-068", "document_id": "gpu-block-and-warp", "position": 68, "token_count": 151, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Next steps"], "file_path": "gpu/block-and-warp.mdx", "url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp", "title": "GPU block and warp operations and synchronization", "category": null, "tags": [], "section_url": "https://docs.modular.com/mojo/manual/gpu/block-and-warp#next-steps"}}
