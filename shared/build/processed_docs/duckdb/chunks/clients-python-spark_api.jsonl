{"chunk_id": "clients-python-spark_api-000", "document_id": "clients-python-spark_api", "content": "The DuckDB Spark API implements the [PySpark API](https://spark.apache.org/docs/3.5.0/api/python/reference/index.html), allowing you to use the familiar Spark API to interact with DuckDB.\nAll statements are translated to DuckDB's internal plans using our [relational API]({% link docs/stable/clients/python/relational_api.md %}) and executed using DuckDB's query engine.\n\n> Warning The DuckDB Spark API is currently experimental and features are still missing. We are very interested in feedback. Please report any functionality that you are missing, either through [Discord](https://discord.duckdb.org) or on [GitHub](https://github.com/duckdb/duckdb/issues).", "position": 0, "token_count": 186, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-spark_api-000", "document_id": "clients-python-spark_api", "position": 0, "token_count": 186, "has_code": false, "overlap_with_previous": false, "section_hierarchy": [], "file_path": "clients/python/spark_api.md", "url": "/clients/python/spark_api", "title": "Spark API", "category": null, "tags": [], "section_url": "/clients/python/spark_api"}}
{"chunk_id": "clients-python-spark_api-001", "document_id": "clients-python-spark_api", "content": "## Example\n\n```python\nfrom duckdb.experimental.spark.sql import SparkSession as session\nfrom duckdb.experimental.spark.sql.functions import lit, col\nimport pandas as pd\n\nspark = session.builder.getOrCreate()\n\npandas_df = pd.DataFrame({\n 'age': [34, 45, 23, 56],\n 'name': ['Joan', 'Peter', 'John', 'Bob']\n})\n\ndf = spark.createDataFrame(pandas_df)\ndf = df.withColumn(\n 'location', lit('Seattle')\n)\nres = df.select(\n col('age'),\n col('location')\n).collect()\n\nprint(res)\n```\n\n```text\n[\n Row(age=34, location='Seattle'),\n Row(age=45, location='Seattle'),\n Row(age=23, location='Seattle'),\n Row(age=56, location='Seattle')\n]\n```", "position": 1, "token_count": 234, "has_code": true, "section_hierarchy": ["Example"], "metadata": {"chunk_id": "clients-python-spark_api-001", "document_id": "clients-python-spark_api", "position": 1, "token_count": 234, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Example"], "file_path": "clients/python/spark_api.md", "url": "/clients/python/spark_api", "title": "Spark API", "category": null, "tags": [], "section_url": "/clients/python/spark_api#example"}}
{"chunk_id": "clients-python-spark_api-002", "document_id": "clients-python-spark_api", "content": "## Contribution Guidelines\n\nContributions to the experimental Spark API are welcome.\nWhen making a contribution, please follow these guidelines:\n\n* Instead of using temporary files, use our `pytest` testing framework.\n* When adding new functions, ensure that method signatures comply with those in the [PySpark API](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html).", "position": 2, "token_count": 96, "has_code": false, "section_hierarchy": ["Contribution Guidelines"], "metadata": {"chunk_id": "clients-python-spark_api-002", "document_id": "clients-python-spark_api", "position": 2, "token_count": 96, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Contribution Guidelines"], "file_path": "clients/python/spark_api.md", "url": "/clients/python/spark_api", "title": "Spark API", "category": null, "tags": [], "section_url": "/clients/python/spark_api#contribution-guidelines"}}
