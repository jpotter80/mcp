{"chunk_id": "clients-python-data_ingestion-000", "document_id": "clients-python-data_ingestion", "content": "This page contains examples for data ingestion to Python using DuckDB. First, import the DuckDB page:\n\n```python\nimport duckdb\n```\n\nThen, proceed with any of the following sections.", "position": 0, "token_count": 45, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-data_ingestion-000", "document_id": "clients-python-data_ingestion", "position": 0, "token_count": 45, "has_code": true, "overlap_with_previous": false, "section_hierarchy": [], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion"}}
{"chunk_id": "clients-python-data_ingestion-001", "document_id": "clients-python-data_ingestion", "content": "## CSV Files\n\nCSV files can be read using the `read_csv` function, called either from within Python or directly from within SQL. By default, the `read_csv` function attempts to auto-detect the CSV settings by sampling from the provided file.\n\nRead from a file using fully auto-detected settings:\n\n```python\nduckdb.read_csv(\"example.csv\")\n```\n\nRead multiple CSV files from a folder:\n\n```python\nduckdb.read_csv(\"folder/*.csv\")\n```\n\nSpecify options on how the CSV is formatted internally:\n\n```python\nduckdb.read_csv(\"example.csv\", header = False, sep = \",\")\n```\n\nOverride types of the first two columns:\n\n```python\nduckdb.read_csv(\"example.csv\", dtype = [\"int\", \"varchar\"])", "position": 1, "token_count": 214, "has_code": true, "section_hierarchy": ["CSV Files"], "metadata": {"chunk_id": "clients-python-data_ingestion-001", "document_id": "clients-python-data_ingestion", "position": 1, "token_count": 214, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["CSV Files"], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion#csv-files"}}
{"chunk_id": "clients-python-data_ingestion-002", "document_id": "clients-python-data_ingestion", "content": "```\n\nOverride types of the first two columns:\n\n```python\nduckdb.read_csv(\"example.csv\", dtype = [\"int\", \"varchar\"])\n```\n\nDirectly read a CSV file from within SQL:\n\n```python\nduckdb.sql(\"SELECT * FROM 'example.csv'\")\n```\n\nCall `read_csv` from within SQL:\n\n```python\nduckdb.sql(\"SELECT * FROM read_csv('example.csv')\")\n```\n\nSee the [CSV Import]({% link docs/stable/data/csv/overview.md %}) page for more information.", "position": 2, "token_count": 158, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-data_ingestion-002", "document_id": "clients-python-data_ingestion", "position": 2, "token_count": 158, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion"}}
{"chunk_id": "clients-python-data_ingestion-003", "document_id": "clients-python-data_ingestion", "content": "## Parquet Files\n\nParquet files can be read using the `read_parquet` function, called either from within Python or directly from within SQL.\n\nRead from a single Parquet file:\n\n```python\nduckdb.read_parquet(\"example.parquet\")\n```\n\nRead multiple Parquet files from a folder:\n\n```python\nduckdb.read_parquet(\"folder/*.parquet\")\n```\n\nRead a Parquet file over [https]({% link docs/stable/core_extensions/httpfs/overview.md %}):\n\n```python\nduckdb.read_parquet(\"https://some.url/some_file.parquet\")\n```\n\nRead a list of Parquet files:\n\n```python\nduckdb.read_parquet([\"file1.parquet\", \"file2.parquet\", \"file3.parquet\"])", "position": 3, "token_count": 208, "has_code": true, "section_hierarchy": ["Parquet Files"], "metadata": {"chunk_id": "clients-python-data_ingestion-003", "document_id": "clients-python-data_ingestion", "position": 3, "token_count": 208, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Parquet Files"], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion#parquet-files"}}
{"chunk_id": "clients-python-data_ingestion-004", "document_id": "clients-python-data_ingestion", "content": "```\n\nDirectly read a Parquet file from within SQL:\n\n```python\nduckdb.sql(\"SELECT * FROM 'example.parquet'\")\n```\n\nCall `read_parquet` from within SQL:\n\n```python\nduckdb.sql(\"SELECT * FROM read_parquet('example.parquet')\")\n```\n\nSee the [Parquet Loading]({% link docs/stable/data/parquet/overview.md %}) page for more information.", "position": 4, "token_count": 112, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-data_ingestion-004", "document_id": "clients-python-data_ingestion", "position": 4, "token_count": 112, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion"}}
{"chunk_id": "clients-python-data_ingestion-005", "document_id": "clients-python-data_ingestion", "content": "## JSON Files\n\nJSON files can be read using the `read_json` function, called either from within Python or directly from within SQL. By default, the `read_json` function will automatically detect if a file contains newline-delimited JSON or regular JSON, and will detect the schema of the objects stored within the JSON file.\n\nRead from a single JSON file:\n\n```python\nduckdb.read_json(\"example.json\")\n```\n\nRead multiple JSON files from a folder:\n\n```python\nduckdb.read_json(\"folder/*.json\")\n```\n\nDirectly read a JSON file from within SQL:\n\n```python\nduckdb.sql(\"SELECT * FROM 'example.json'\")\n```\n\nCall `read_json` from within SQL:\n\n```python\nduckdb.sql(\"SELECT * FROM read_json_auto('example.json')\")\n```", "position": 5, "token_count": 221, "has_code": true, "section_hierarchy": ["JSON Files"], "metadata": {"chunk_id": "clients-python-data_ingestion-005", "document_id": "clients-python-data_ingestion", "position": 5, "token_count": 221, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["JSON Files"], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion#json-files"}}
{"chunk_id": "clients-python-data_ingestion-006", "document_id": "clients-python-data_ingestion", "content": "## Directly Accessing DataFrames and Arrow Objects\n\nDuckDB is automatically able to query certain Python variables by referring to their variable name (as if it was a table).\nThese types include the following: Pandas DataFrame, Polars DataFrame, Polars LazyFrame, NumPy arrays, [relations]({% link docs/stable/clients/python/relational_api.md %}), and Arrow objects.\n\nOnly variables that are visible to Python code at the location of the `sql()` or `execute()` call can be used in this manner.\nAccessing these variables is made possible by [replacement scans]({% link docs/stable/clients/c/replacement_scans.md %}). To disable replacement scans entirely, use:\n\n```sql\nSET python_enable_replacements = false;", "position": 6, "token_count": 181, "has_code": true, "section_hierarchy": ["Directly Accessing DataFrames and Arrow Objects"], "metadata": {"chunk_id": "clients-python-data_ingestion-006", "document_id": "clients-python-data_ingestion", "position": 6, "token_count": 181, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Directly Accessing DataFrames and Arrow Objects"], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion#directly-accessing-dataframes-and-arrow-objects"}}
{"chunk_id": "clients-python-data_ingestion-007", "document_id": "clients-python-data_ingestion", "content": "```\n\nDuckDB supports querying multiple types of Apache Arrow objects including [tables](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html), [datasets](https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Dataset.html), [RecordBatchReaders](https://arrow.apache.org/docs/python/generated/pyarrow.ipc.RecordBatchStreamReader.html), and [scanners](https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Scanner.html). See the Python [guides]({% link docs/stable/guides/overview.md %}#python-client) for more examples.\n\n```python\nimport duckdb\nimport pandas as pd", "position": 7, "token_count": 203, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-data_ingestion-007", "document_id": "clients-python-data_ingestion", "position": 7, "token_count": 203, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion"}}
{"chunk_id": "clients-python-data_ingestion-008", "document_id": "clients-python-data_ingestion", "content": "```python\nimport duckdb\nimport pandas as pd\n\ntest_df = pd.DataFrame.from_dict({\"i\": [1, 2, 3, 4], \"j\": [\"one\", \"two\", \"three\", \"four\"]})\nprint(duckdb.sql(\"SELECT * FROM test_df\").fetchall())", "position": 8, "token_count": 90, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-data_ingestion-008", "document_id": "clients-python-data_ingestion", "position": 8, "token_count": 90, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion"}}
{"chunk_id": "clients-python-data_ingestion-009", "document_id": "clients-python-data_ingestion", "content": "```\n\n```text\n[(1, 'one'), (2, 'two'), (3, 'three'), (4, 'four')]", "position": 9, "token_count": 42, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-data_ingestion-009", "document_id": "clients-python-data_ingestion", "position": 9, "token_count": 42, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion"}}
{"chunk_id": "clients-python-data_ingestion-010", "document_id": "clients-python-data_ingestion", "content": "```\n\nDuckDB also supports “registering” a DataFrame or Arrow object as a virtual table, comparable to a SQL `VIEW`. This is useful when querying a DataFrame/Arrow object that is stored in another way (as a class variable, or a value in a dictionary). Below is a Pandas example:\n\nIf your Pandas DataFrame is stored in another location, here is an example of manually registering it:\n\n```python\nimport duckdb\nimport pandas as pd\n\nmy_dictionary = {}\nmy_dictionary[\"test_df\"] = pd.DataFrame.from_dict({\"i\": [1, 2, 3, 4], \"j\": [\"one\", \"two\", \"three\", \"four\"]})\nduckdb.register(\"test_df_view\", my_dictionary[\"test_df\"])\nprint(duckdb.sql(\"SELECT * FROM test_df_view\").fetchall())", "position": 10, "token_count": 220, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-data_ingestion-010", "document_id": "clients-python-data_ingestion", "position": 10, "token_count": 220, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion"}}
{"chunk_id": "clients-python-data_ingestion-011", "document_id": "clients-python-data_ingestion", "content": "```\n\n```text\n[(1, 'one'), (2, 'two'), (3, 'three'), (4, 'four')]\n```\n\nYou can also create a persistent table in DuckDB from the contents of the DataFrame (or the view):\n\n```python", "position": 11, "token_count": 72, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-python-data_ingestion-011", "document_id": "clients-python-data_ingestion", "position": 11, "token_count": 72, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion"}}
{"chunk_id": "clients-python-data_ingestion-012", "document_id": "clients-python-data_ingestion", "content": "# create a new table from the contents of a DataFrame\ncon.execute(\"CREATE TABLE test_df_table AS SELECT * FROM test_df\")\n# insert into an existing table from the contents of a DataFrame\ncon.execute(\"INSERT INTO test_df_table SELECT * FROM test_df\")\n```\n\n### Pandas DataFrames – `object` Columns\n\n`pandas.DataFrame` columns of an `object` dtype require some special care, since this stores values of arbitrary type.\nTo convert these columns to DuckDB, we first go through an analyze phase before converting the values.\nIn this analyze phase a sample of all the rows of the column are analyzed to determine the target type.\nThis sample size is by default set to 1000.\nIf the type picked during the analyze step is incorrect, this will result in `Invalid Input Error: Failed to cast value`, in which case you will need to increase the sample size.\nThe sample size can be changed by setting the `pandas_analyze_sample` config option.\n\n```python", "position": 12, "token_count": 231, "has_code": true, "section_hierarchy": ["Pandas DataFrames – `object` Columns"], "metadata": {"chunk_id": "clients-python-data_ingestion-012", "document_id": "clients-python-data_ingestion", "position": 12, "token_count": 231, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Pandas DataFrames – `object` Columns"], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion#pandas-dataframes--object-columns"}}
{"chunk_id": "clients-python-data_ingestion-013", "document_id": "clients-python-data_ingestion", "content": "# example setting the sample size to 100k\nduckdb.execute(\"SET GLOBAL pandas_analyze_sample = 100_000\")\n```\n\n### Registering Objects\n\nYou can register Python objects as DuckDB tables using the [`DuckDBPyConnection.register()` function]({% link docs/stable/clients/python/reference/index.md %}#duckdb.DuckDBPyConnection.register).\n\nThe precedence of objects with the same name is as follows:\n\n* Objects explicitly registered via `DuckDBPyConnection.register()`\n* Native DuckDB tables and views\n* [Replacement scans]({% link docs/stable/clients/c/replacement_scans.md %})", "position": 13, "token_count": 161, "has_code": true, "section_hierarchy": ["Registering Objects"], "metadata": {"chunk_id": "clients-python-data_ingestion-013", "document_id": "clients-python-data_ingestion", "position": 13, "token_count": 161, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Registering Objects"], "file_path": "clients/python/data_ingestion.md", "url": "/clients/python/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/python/data_ingestion#registering-objects"}}
