{"chunk_id": "data-overview-000", "document_id": "data-overview", "content": "The first step to using a database system is to insert data into that system.\nDuckDB can directly connect to [many popular data sources]({% link docs/stable/data/data_sources.md %}) and offers several data ingestion methods that allow you to easily and efficiently fill up the database.\nOn this page, we provide an overview of these methods so you can select which one is best suited for your use case.\n\n## `INSERT` Statements\n\n`INSERT` statements are the standard way of loading data into a database system. They are suitable for quick prototyping, but should be avoided for bulk loading as they have significant per-row overhead.\n\n```sql\nINSERT INTO people VALUES (1, 'Mark');\n```\n\nFor a more detailed description, see the [page on the `INSERT` statement]({% link docs/stable/data/insert.md %}).", "position": 0, "token_count": 195, "has_code": true, "section_hierarchy": ["`INSERT` Statements"], "metadata": {"chunk_id": "data-overview-000", "document_id": "data-overview", "position": 0, "token_count": 195, "has_code": true, "overlap_with_previous": false, "section_hierarchy": ["`INSERT` Statements"], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview#insert-statements"}}
{"chunk_id": "data-overview-001", "document_id": "data-overview", "content": "## File Loading: Relative Paths\n\nUse the configuration option [`file_search_path`]({% link docs/stable/configuration/overview.md %}#local-configuration-options) to configure to which “root directories” relative paths are expanded on.\nIf `file_search_path` is not set, the working directory is used as the basis for relative paths.", "position": 1, "token_count": 87, "has_code": false, "section_hierarchy": ["File Loading: Relative Paths"], "metadata": {"chunk_id": "data-overview-001", "document_id": "data-overview", "position": 1, "token_count": 87, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["File Loading: Relative Paths"], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview#file-loading-relative-paths"}}
{"chunk_id": "data-overview-002", "document_id": "data-overview", "content": "## File Formats", "position": 2, "token_count": 6, "has_code": false, "section_hierarchy": ["File Formats"], "metadata": {"chunk_id": "data-overview-002", "document_id": "data-overview", "position": 2, "token_count": 6, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["File Formats"], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview#file-formats"}}
{"chunk_id": "data-overview-003", "document_id": "data-overview", "content": "### CSV Loading\n\nData can be efficiently loaded from CSV files using several methods. The simplest is to use the CSV file's name:\n\n```sql\nSELECT * FROM 'test.csv';\n```\n\nAlternatively, use the [`read_csv` function]({% link docs/stable/data/csv/overview.md %}) to pass along options:\n\n```sql\nSELECT * FROM read_csv('test.csv', header = false);\n```\n\nOr use the [`COPY` statement]({% link docs/stable/sql/statements/copy.md %}#copy--from):\n\n```sql\nCOPY tbl FROM 'test.csv' (HEADER false);\n```\n\nIt is also possible to read data directly from **compressed CSV files** (e.g., compressed with [gzip](https://www.gzip.org/)):\n\n```sql\nSELECT * FROM 'test.csv.gz';", "position": 3, "token_count": 235, "has_code": true, "section_hierarchy": ["CSV Loading"], "metadata": {"chunk_id": "data-overview-003", "document_id": "data-overview", "position": 3, "token_count": 235, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["CSV Loading"], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview#csv-loading"}}
{"chunk_id": "data-overview-004", "document_id": "data-overview", "content": "```\n\nDuckDB can create a table from the loaded data using the [`CREATE TABLE ... AS SELECT` statement]({% link docs/stable/sql/statements/create_table.md %}#create-table--as-select-ctas):\n\n```sql\nCREATE TABLE test AS\n SELECT * FROM 'test.csv';\n```\n\nFor more details, see the [page on CSV loading]({% link docs/stable/data/csv/overview.md %}).", "position": 4, "token_count": 118, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-overview-004", "document_id": "data-overview", "position": 4, "token_count": 118, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview"}}
{"chunk_id": "data-overview-005", "document_id": "data-overview", "content": "### Parquet Loading\n\nParquet files can be efficiently loaded and queried using their filename:\n\n```sql\nSELECT * FROM 'test.parquet';\n```\n\nAlternatively, use the [`read_parquet` function]({% link docs/stable/data/parquet/overview.md %}):\n\n```sql\nSELECT * FROM read_parquet('test.parquet');\n```\n\nOr use the [`COPY` statement]({% link docs/stable/sql/statements/copy.md %}#copy--from):\n\n```sql\nCOPY tbl FROM 'test.parquet';\n```\n\nFor more details, see the [page on Parquet loading]({% link docs/stable/data/parquet/overview.md %}).", "position": 5, "token_count": 183, "has_code": true, "section_hierarchy": ["Parquet Loading"], "metadata": {"chunk_id": "data-overview-005", "document_id": "data-overview", "position": 5, "token_count": 183, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Parquet Loading"], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview#parquet-loading"}}
{"chunk_id": "data-overview-006", "document_id": "data-overview", "content": "### JSON Loading\n\nJSON files can be efficiently loaded and queried using their filename:\n\n```sql\nSELECT * FROM 'test.json';\n```\n\nAlternatively, use the [`read_json_auto` function]({% link docs/stable/data/json/overview.md %}):\n\n```sql\nSELECT * FROM read_json_auto('test.json');\n```\n\nOr use the [`COPY` statement]({% link docs/stable/sql/statements/copy.md %}#copy--from):\n\n```sql\nCOPY tbl FROM 'test.json';\n```\n\nFor more details, see the [page on JSON loading]({% link docs/stable/data/json/overview.md %}).", "position": 6, "token_count": 187, "has_code": true, "section_hierarchy": ["JSON Loading"], "metadata": {"chunk_id": "data-overview-006", "document_id": "data-overview", "position": 6, "token_count": 187, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["JSON Loading"], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview#json-loading"}}
{"chunk_id": "data-overview-007", "document_id": "data-overview", "content": "### Returning the Filename\n\nSince DuckDB v1.3.0, the CSV, JSON and Parquet readers support the `filename` virtual column:\n\n```sql\nCOPY (FROM (VALUES (42), (43)) t(x)) TO 'test.parquet';\nSELECT *, filename FROM 'test.parquet';\n```", "position": 7, "token_count": 84, "has_code": true, "section_hierarchy": ["Returning the Filename"], "metadata": {"chunk_id": "data-overview-007", "document_id": "data-overview", "position": 7, "token_count": 84, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Returning the Filename"], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview#returning-the-filename"}}
{"chunk_id": "data-overview-008", "document_id": "data-overview", "content": "## Appender\n\nIn several APIs (C, C++, Go, Java, and Rust), the [Appender]({% link docs/stable/data/appender.md %}) can be used as an alternative for bulk data loading.\nThis class can be used to efficiently add rows to the database system without using SQL statements.", "position": 8, "token_count": 80, "has_code": false, "section_hierarchy": ["Appender"], "metadata": {"chunk_id": "data-overview-008", "document_id": "data-overview", "position": 8, "token_count": 80, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Appender"], "file_path": "data/overview.md", "url": "/data/overview", "title": "Importing Data", "category": null, "tags": [], "section_url": "/data/overview#appender"}}
