{"chunk_id": "connect-concurrency-000", "document_id": "connect-concurrency", "content": "## Handling Concurrency\n\nDuckDB has two configurable options for concurrency:\n\n1. One process can both read and write to the database.\n2. Multiple processes can read from the database, but no processes can write ([`access_mode = 'READ_ONLY'`]({% link docs/stable/configuration/overview.md %}#configuration-reference)).\n\nWhen using option 1, DuckDB supports multiple writer threads using a combination of [MVCC (Multi-Version Concurrency Control)](https://en.wikipedia.org/wiki/Multiversion_concurrency_control) and optimistic concurrency control (see [Concurrency within a Single Process](#concurrency-within-a-single-process)), but all within that single writer process. The reason for this concurrency model is to allow for the caching of data in RAM for faster analytical queries, rather than going back and forth to disk during each query. It also allows the caching of functions pointers, the database catalog, and other items so that subsequent queries on the same connection are faster.\n\n> DuckDB is optimized for bulk operations, so executing many small transactions is not a primary design goal.", "position": 0, "token_count": 253, "has_code": false, "section_hierarchy": ["Handling Concurrency"], "metadata": {"chunk_id": "connect-concurrency-000", "document_id": "connect-concurrency", "position": 0, "token_count": 253, "has_code": false, "overlap_with_previous": false, "section_hierarchy": ["Handling Concurrency"], "file_path": "connect/concurrency.md", "url": "/connect/concurrency", "title": "Concurrency", "category": null, "tags": [], "section_url": "/connect/concurrency#handling-concurrency"}}
{"chunk_id": "connect-concurrency-001", "document_id": "connect-concurrency", "content": "## Concurrency within a Single Process\n\nDuckDB supports concurrency within a single process according to the following rules. As long as there are no write conflicts, multiple concurrent writes will succeed. Appends will never conflict, even on the same table. Multiple threads can also simultaneously update separate tables or separate subsets of the same table. Optimistic concurrency control comes into play when two threads attempt to edit (update or delete) the same row at the same time. In that situation, the second thread to attempt the edit will fail with a conflict error.", "position": 1, "token_count": 112, "has_code": false, "section_hierarchy": ["Concurrency within a Single Process"], "metadata": {"chunk_id": "connect-concurrency-001", "document_id": "connect-concurrency", "position": 1, "token_count": 112, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Concurrency within a Single Process"], "file_path": "connect/concurrency.md", "url": "/connect/concurrency", "title": "Concurrency", "category": null, "tags": [], "section_url": "/connect/concurrency#concurrency-within-a-single-process"}}
{"chunk_id": "connect-concurrency-002", "document_id": "connect-concurrency", "content": "## Writing to DuckDB from Multiple Processes\n\nWriting to DuckDB from multiple processes is not supported automatically and is not a primary design goal (see [Handling Concurrency](#handling-concurrency)).", "position": 2, "token_count": 43, "has_code": false, "section_hierarchy": ["Writing to DuckDB from Multiple Processes"], "metadata": {"chunk_id": "connect-concurrency-002", "document_id": "connect-concurrency", "position": 2, "token_count": 43, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Writing to DuckDB from Multiple Processes"], "file_path": "connect/concurrency.md", "url": "/connect/concurrency", "title": "Concurrency", "category": null, "tags": [], "section_url": "/connect/concurrency#writing-to-duckdb-from-multiple-processes"}}
{"chunk_id": "connect-concurrency-003", "document_id": "connect-concurrency", "content": "If multiple processes must write to the same file, several design patterns are possible, but would need to be implemented in application logic. For example, each process could acquire a cross-process mutex lock, then open the database in read/write mode and close it when the query is complete. Instead of using a mutex lock, each process could instead retry the connection if another process is already connected to the database (being sure to close the connection upon query completion). Another alternative would be to do multi-process transactions on a MySQL, PostgreSQL, or SQLite database, and use DuckDB's [MySQL]({% link docs/stable/core_extensions/mysql.md %}), [PostgreSQL]({% link docs/stable/core_extensions/postgres.md %}), or [SQLite]({% link docs/stable/core_extensions/sqlite.md %}) extensions to execute analytical queries on that data periodically.", "position": 3, "token_count": 226, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "connect-concurrency-003", "document_id": "connect-concurrency", "position": 3, "token_count": 226, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "connect/concurrency.md", "url": "/connect/concurrency", "title": "Concurrency", "category": null, "tags": [], "section_url": "/connect/concurrency"}}
{"chunk_id": "connect-concurrency-004", "document_id": "connect-concurrency", "content": "Additional options include writing data to Parquet files and using DuckDB's ability to [read multiple Parquet files]({% link docs/stable/data/parquet/overview.md %}), taking a similar approach with [CSV files]({% link docs/stable/data/csv/overview.md %}), or creating a web server to receive requests and manage reads and writes to DuckDB.", "position": 4, "token_count": 95, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "connect-concurrency-004", "document_id": "connect-concurrency", "position": 4, "token_count": 95, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "connect/concurrency.md", "url": "/connect/concurrency", "title": "Concurrency", "category": null, "tags": [], "section_url": "/connect/concurrency"}}
{"chunk_id": "connect-concurrency-005", "document_id": "connect-concurrency", "content": "## Optimistic Concurrency Control\n\nDuckDB uses [optimistic concurrency control](https://en.wikipedia.org/wiki/Optimistic_concurrency_control), an approach generally considered to be the best fit for read-intensive analytical database systems as it speeds up read query processing. As a result any transactions that modify the same rows at the same time will cause a transaction conflict error:\n\n```console\nTransaction conflict: cannot update a table that has been altered!\n```\n\n> Tip A common workaround when a transaction conflict is encountered is to rerun the transaction.", "position": 5, "token_count": 119, "has_code": true, "section_hierarchy": ["Optimistic Concurrency Control"], "metadata": {"chunk_id": "connect-concurrency-005", "document_id": "connect-concurrency", "position": 5, "token_count": 119, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Optimistic Concurrency Control"], "file_path": "connect/concurrency.md", "url": "/connect/concurrency", "title": "Concurrency", "category": null, "tags": [], "section_url": "/connect/concurrency#optimistic-concurrency-control"}}
