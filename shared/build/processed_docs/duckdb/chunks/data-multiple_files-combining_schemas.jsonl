{"chunk_id": "data-multiple_files-combining_schemas-000", "document_id": "data-multiple_files-combining_schemas", "content": "## Examples\n\nRead a set of CSV files combining columns by position:\n\n```sql\nSELECT * FROM read_csv('flights*.csv');\n```\n\nRead a set of CSV files combining columns by name:\n\n```sql\nSELECT * FROM read_csv('flights*.csv', union_by_name = true);\n```\n\n## Combining Schemas\n\nWhen reading from multiple files, we have to **combine schemas** from those files. That is because each file has its own schema that can differ from the other files. DuckDB offers two ways of unifying schemas of multiple files: **by column position** and **by column name**.\n\nBy default, DuckDB reads the schema of the first file provided, and then unifies columns in subsequent files by column position. This works correctly as long as all files have the same schema. If the schema of the files differs, you might want to use the `union_by_name` option to allow DuckDB to construct the schema by reading all of the names instead.\n\nBelow is an example of how both methods work.", "position": 0, "token_count": 252, "has_code": true, "section_hierarchy": ["Combining Schemas"], "metadata": {"chunk_id": "data-multiple_files-combining_schemas-000", "document_id": "data-multiple_files-combining_schemas", "position": 0, "token_count": 252, "has_code": true, "overlap_with_previous": false, "section_hierarchy": ["Combining Schemas"], "file_path": "data/multiple_files/combining_schemas.md", "url": "/data/multiple_files/combining_schemas", "title": "Combining Schemas", "category": null, "tags": [], "section_url": "/data/multiple_files/combining_schemas#combining-schemas"}}
{"chunk_id": "data-multiple_files-combining_schemas-001", "document_id": "data-multiple_files-combining_schemas", "content": "## Union by Position\n\nBy default, DuckDB unifies the columns of these different files **by position**. This means that the first column in each file is combined together, as well as the second column in each file, etc. For example, consider the following two files.\n\n[`flights1.csv`]({% link data/flights1.csv %}):\n\n```csv\nFlightDate|UniqueCarrier|OriginCityName|DestCityName\n1988-01-01|AA|New York, NY|Los Angeles, CA\n1988-01-02|AA|New York, NY|Los Angeles, CA\n```\n\n[`flights2.csv`]({% link data/flights2.csv %}):\n\n```csv\nFlightDate|UniqueCarrier|OriginCityName|DestCityName\n1988-01-03|AA|New York, NY|Los Angeles, CA", "position": 1, "token_count": 203, "has_code": true, "section_hierarchy": ["Union by Position"], "metadata": {"chunk_id": "data-multiple_files-combining_schemas-001", "document_id": "data-multiple_files-combining_schemas", "position": 1, "token_count": 203, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Union by Position"], "file_path": "data/multiple_files/combining_schemas.md", "url": "/data/multiple_files/combining_schemas", "title": "Combining Schemas", "category": null, "tags": [], "section_url": "/data/multiple_files/combining_schemas#union-by-position"}}
{"chunk_id": "data-multiple_files-combining_schemas-002", "document_id": "data-multiple_files-combining_schemas", "content": "```\n\nReading the two files at the same time will produce the following result set:\n\n| FlightDate | UniqueCarrier | OriginCityName | DestCityName |\n|------------|---------------|----------------|-----------------|\n| 1988-01-01 | AA | New York, NY | Los Angeles, CA |\n| 1988-01-02 | AA | New York, NY | Los Angeles, CA |\n| 1988-01-03 | AA | New York, NY | Los Angeles, CA |\n\nThis is equivalent to the SQL construct [`UNION ALL`]({% link docs/stable/sql/query_syntax/setops.md %}#union-all).", "position": 2, "token_count": 199, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-multiple_files-combining_schemas-002", "document_id": "data-multiple_files-combining_schemas", "position": 2, "token_count": 199, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/multiple_files/combining_schemas.md", "url": "/data/multiple_files/combining_schemas", "title": "Combining Schemas", "category": null, "tags": [], "section_url": "/data/multiple_files/combining_schemas"}}
{"chunk_id": "data-multiple_files-combining_schemas-003", "document_id": "data-multiple_files-combining_schemas", "content": "## Union by Name\n\nIf you are processing multiple files that have different schemas, perhaps because columns have been added or renamed, it might be desirable to unify the columns of different files **by name** instead. This can be done by providing the `union_by_name` option. For example, consider the following two files, where `flights4.csv` has an extra column (`UniqueCarrier`).\n\n[`flights3.csv`]({% link data/flights3.csv %}):\n\n```csv\nFlightDate|OriginCityName|DestCityName\n1988-01-01|New York, NY|Los Angeles, CA\n1988-01-02|New York, NY|Los Angeles, CA\n```\n\n[`flights4.csv`]({% link data/flights4.csv %}):\n\n```csv\nFlightDate|UniqueCarrier|OriginCityName|DestCityName\n1988-01-03|AA|New York, NY|Los Angeles, CA", "position": 3, "token_count": 228, "has_code": true, "section_hierarchy": ["Union by Name"], "metadata": {"chunk_id": "data-multiple_files-combining_schemas-003", "document_id": "data-multiple_files-combining_schemas", "position": 3, "token_count": 228, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Union by Name"], "file_path": "data/multiple_files/combining_schemas.md", "url": "/data/multiple_files/combining_schemas", "title": "Combining Schemas", "category": null, "tags": [], "section_url": "/data/multiple_files/combining_schemas#union-by-name"}}
{"chunk_id": "data-multiple_files-combining_schemas-004", "document_id": "data-multiple_files-combining_schemas", "content": "```\n\nReading these when unifying column names **by position** results in an error â€“ as the two files have a different number of columns. When specifying the `union_by_name` option, the columns are correctly unified, and any missing values are set to `NULL`.\n\n```sql\nSELECT * FROM read_csv(['flights3.csv', 'flights4.csv'], union_by_name = true);", "position": 4, "token_count": 103, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-multiple_files-combining_schemas-004", "document_id": "data-multiple_files-combining_schemas", "position": 4, "token_count": 103, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/multiple_files/combining_schemas.md", "url": "/data/multiple_files/combining_schemas", "title": "Combining Schemas", "category": null, "tags": [], "section_url": "/data/multiple_files/combining_schemas"}}
{"chunk_id": "data-multiple_files-combining_schemas-005", "document_id": "data-multiple_files-combining_schemas", "content": "```\n\n| FlightDate | OriginCityName | DestCityName | UniqueCarrier |\n|------------|----------------|-----------------|---------------|\n| 1988-01-01 | New York, NY | Los Angeles, CA | NULL |\n| 1988-01-02 | New York, NY | Los Angeles, CA | NULL |\n| 1988-01-03 | New York, NY | Los Angeles, CA | AA |\n\nThis is equivalent to the SQL construct [`UNION ALL BY NAME`]({% link docs/stable/sql/query_syntax/setops.md %}#union-all-by-name).\n\n> Using the `union_by_name` option increases memory consumption.", "position": 5, "token_count": 205, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-multiple_files-combining_schemas-005", "document_id": "data-multiple_files-combining_schemas", "position": 5, "token_count": 205, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/multiple_files/combining_schemas.md", "url": "/data/multiple_files/combining_schemas", "title": "Combining Schemas", "category": null, "tags": [], "section_url": "/data/multiple_files/combining_schemas"}}
