{"chunk_id": "clients-wasm-data_ingestion-000", "document_id": "clients-wasm-data_ingestion", "content": "DuckDB-Wasm has multiple ways to import data, depending on the format of the data.\n\nThere are two steps to import data into DuckDB.", "position": 0, "token_count": 33, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-000", "document_id": "clients-wasm-data_ingestion", "position": 0, "token_count": 33, "has_code": false, "overlap_with_previous": false, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-001", "document_id": "clients-wasm-data_ingestion", "content": "There are two steps to import data into DuckDB.\n\nFirst, the data file is imported into a local file system using register functions ([registerEmptyFileBuffer](https://shell.duckdb.org/docs/classes/index.AsyncDuckDB.html#registerEmptyFileBuffer), [registerFileBuffer](https://shell.duckdb.org/docs/classes/index.AsyncDuckDB.html#registerFileBuffer), [registerFileHandle](https://shell.duckdb.org/docs/classes/index.AsyncDuckDB.html#registerFileHandle), [registerFileText](https://shell.duckdb.org/docs/classes/index.AsyncDuckDB.html#registerFileText), [registerFileURL](https://shell.duckdb.org/docs/classes/index.AsyncDuckDB.html#registerFileURL)).", "position": 1, "token_count": 239, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-001", "document_id": "clients-wasm-data_ingestion", "position": 1, "token_count": 239, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-002", "document_id": "clients-wasm-data_ingestion", "content": "Then, the data file is imported into DuckDB using insert functions ([insertArrowFromIPCStream](https://shell.duckdb.org/docs/classes/index.AsyncDuckDBConnection.html#insertArrowFromIPCStream), [insertArrowTable](https://shell.duckdb.org/docs/classes/index.AsyncDuckDBConnection.html#insertArrowTable), [insertCSVFromPath](https://shell.duckdb.org/docs/classes/index.AsyncDuckDBConnection.html#insertCSVFromPath), [insertJSONFromPath](https://shell.duckdb.org/docs/classes/index.AsyncDuckDBConnection.html#insertJSONFromPath)) or directly using FROM SQL query (using extensions like Parquet or [Wasm-flavored httpfs](#httpfs-wasm-flavored)).", "position": 2, "token_count": 233, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-002", "document_id": "clients-wasm-data_ingestion", "position": 2, "token_count": 233, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-003", "document_id": "clients-wasm-data_ingestion", "content": "[Insert statements]({% link docs/stable/data/insert.md %}) can also be used to import data.", "position": 3, "token_count": 31, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-003", "document_id": "clients-wasm-data_ingestion", "position": 3, "token_count": 31, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-004", "document_id": "clients-wasm-data_ingestion", "content": "## Data Import\n\n### Open & Close Connection\n\n```ts\n// Create a new connection\nconst c = await db.connect();\n\n// ... import data\n\n// Close the connection to release memory\nawait c.close();\n```", "position": 4, "token_count": 59, "has_code": true, "section_hierarchy": ["Open & Close Connection"], "metadata": {"chunk_id": "clients-wasm-data_ingestion-004", "document_id": "clients-wasm-data_ingestion", "position": 4, "token_count": 59, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Open & Close Connection"], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion#open--close-connection"}}
{"chunk_id": "clients-wasm-data_ingestion-005", "document_id": "clients-wasm-data_ingestion", "content": "### Apache Arrow\n\n```ts\n// Data can be inserted from an existing arrow.Table\n// More Example https://arrow.apache.org/docs/js/\nimport { tableFromArrays } from 'apache-arrow';\n\n// EOS signal according to Arrow IPC streaming format\n// See https://arrow.apache.org/docs/format/Columnar.html#ipc-streaming-format\nconst EOS = new Uint8Array([255, 255, 255, 255, 0, 0, 0, 0]);\n\nconst arrowTable = tableFromArrays({\n id: [1, 2, 3],\n name: ['John', 'Jane', 'Jack'],\n age: [20, 21, 22],\n});\n\nawait c.insertArrowTable(arrowTable, { name: 'arrow_table' });\n// Write EOS\nawait c.insertArrowTable(EOS, { name: 'arrow_table' });", "position": 5, "token_count": 230, "has_code": true, "section_hierarchy": ["Apache Arrow"], "metadata": {"chunk_id": "clients-wasm-data_ingestion-005", "document_id": "clients-wasm-data_ingestion", "position": 5, "token_count": 230, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Apache Arrow"], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion#apache-arrow"}}
{"chunk_id": "clients-wasm-data_ingestion-006", "document_id": "clients-wasm-data_ingestion", "content": "// ..., from a raw Arrow IPC stream\nconst streamResponse = await fetch(`someapi`);\nconst streamReader = streamResponse.body.getReader();\nconst streamInserts = [];\nwhile (true) {\n const { value, done } = await streamReader.read();\n if (done) break;\n streamInserts.push(c.insertArrowFromIPCStream(value, { name: 'streamed' }));\n}\n\n// Write EOS\nstreamInserts.push(c.insertArrowFromIPCStream(EOS, { name: 'streamed' }));\n\nawait Promise.all(streamInserts);", "position": 6, "token_count": 165, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-006", "document_id": "clients-wasm-data_ingestion", "position": 6, "token_count": 165, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-007", "document_id": "clients-wasm-data_ingestion", "content": "```", "position": 7, "token_count": 5, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-007", "document_id": "clients-wasm-data_ingestion", "position": 7, "token_count": 5, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-008", "document_id": "clients-wasm-data_ingestion", "content": "### CSV\n\n```ts\n// ..., from CSV files\n// (interchangeable: registerFile{Text,Buffer,URL,Handle})\nconst csvContent = '1|foo\\n2|bar\\n';\nawait db.registerFileText(`data.csv`, csvContent);\n// ... with typed insert options\nawait c.insertCSVFromPath('data.csv', {\n schema: 'main',\n name: 'foo',\n detect: false,\n header: false,\n delimiter: '|',\n columns: {\n col1: new arrow.Int32(),\n col2: new arrow.Utf8(),\n },\n});\n```", "position": 8, "token_count": 172, "has_code": true, "section_hierarchy": ["CSV"], "metadata": {"chunk_id": "clients-wasm-data_ingestion-008", "document_id": "clients-wasm-data_ingestion", "position": 8, "token_count": 172, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["CSV"], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion#csv"}}
{"chunk_id": "clients-wasm-data_ingestion-009", "document_id": "clients-wasm-data_ingestion", "content": "### JSON\n\n```ts\n// ..., from JSON documents in row-major format\nconst jsonRowContent = [\n { \"col1\": 1, \"col2\": \"foo\" },\n { \"col1\": 2, \"col2\": \"bar\" },\n];\nawait db.registerFileText(\n 'rows.json',\n JSON.stringify(jsonRowContent),\n);\nawait c.insertJSONFromPath('rows.json', { name: 'rows' });\n\n// ... or column-major format\nconst jsonColContent = {\n \"col1\": [1, 2],\n \"col2\": [\"foo\", \"bar\"]\n};\nawait db.registerFileText(\n 'columns.json',\n JSON.stringify(jsonColContent),\n);\nawait c.insertJSONFromPath('columns.json', { name: 'columns' });", "position": 9, "token_count": 235, "has_code": true, "section_hierarchy": ["JSON"], "metadata": {"chunk_id": "clients-wasm-data_ingestion-009", "document_id": "clients-wasm-data_ingestion", "position": 9, "token_count": 235, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["JSON"], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion#json"}}
{"chunk_id": "clients-wasm-data_ingestion-010", "document_id": "clients-wasm-data_ingestion", "content": "// From API\nconst streamResponse = await fetch(`someapi/content.json`);\nawait db.registerFileBuffer('file.json', new Uint8Array(await streamResponse.arrayBuffer()))\nawait c.insertJSONFromPath('file.json', { name: 'JSONContent' });", "position": 10, "token_count": 94, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-010", "document_id": "clients-wasm-data_ingestion", "position": 10, "token_count": 94, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-011", "document_id": "clients-wasm-data_ingestion", "content": "```", "position": 11, "token_count": 5, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-011", "document_id": "clients-wasm-data_ingestion", "position": 11, "token_count": 5, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-012", "document_id": "clients-wasm-data_ingestion", "content": "### Parquet\n\n```ts\n// from Parquet files\n// ...Local\nconst pickedFile: File = letUserPickFile();\nawait db.registerFileHandle('local.parquet', pickedFile, DuckDBDataProtocol.BROWSER_FILEREADER, true);\n// ...Remote\nawait db.registerFileURL('remote.parquet', 'https://origin/remote.parquet', DuckDBDataProtocol.HTTP, false);\n// ... Using Fetch\nconst res = await fetch('https://origin/remote.parquet');\nawait db.registerFileBuffer('buffer.parquet', new Uint8Array(await res.arrayBuffer()));", "position": 12, "token_count": 187, "has_code": true, "section_hierarchy": ["Parquet"], "metadata": {"chunk_id": "clients-wasm-data_ingestion-012", "document_id": "clients-wasm-data_ingestion", "position": 12, "token_count": 187, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Parquet"], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion#parquet"}}
{"chunk_id": "clients-wasm-data_ingestion-013", "document_id": "clients-wasm-data_ingestion", "content": "// ..., by specifying URLs in the SQL text\nawait c.query(`\n CREATE TABLE direct AS\n SELECT * FROM 'https://origin/remote.parquet'\n`);\n// ..., or by executing raw insert statements\nawait c.query(`\n INSERT INTO existing_table\n VALUES (1, 'foo'), (2, 'bar')`);", "position": 13, "token_count": 87, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-013", "document_id": "clients-wasm-data_ingestion", "position": 13, "token_count": 87, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-014", "document_id": "clients-wasm-data_ingestion", "content": "```", "position": 14, "token_count": 5, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "clients-wasm-data_ingestion-014", "document_id": "clients-wasm-data_ingestion", "position": 14, "token_count": 5, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion"}}
{"chunk_id": "clients-wasm-data_ingestion-015", "document_id": "clients-wasm-data_ingestion", "content": "### httpfs (Wasm-Flavored)\n\n```ts\n// ..., by specifying URLs in the SQL text\nawait c.query(`\n CREATE TABLE direct AS\n SELECT * FROM 'https://origin/remote.parquet'\n`);\n```\n\n> Tip If you encounter a Network Error (`Failed to execute 'send' on 'XMLHttpRequest'`) when you try to query files from S3, configure the S3 permission CORS header. For example:\n\n```json\n[\n {\n \"AllowedHeaders\": [\n \"*\"\n ],\n \"AllowedMethods\": [\n \"GET\",\n \"HEAD\"\n ],\n \"AllowedOrigins\": [\n \"*\"\n ],\n \"ExposeHeaders\": [],\n \"MaxAgeSeconds\": 3000\n }\n]\n```\n\n### Insert Statement\n\n```ts\n// ..., or by executing raw insert statements\nawait c.query(`\n INSERT INTO existing_table\n VALUES (1, 'foo'), (2, 'bar')`);\n```", "position": 15, "token_count": 240, "has_code": true, "section_hierarchy": ["Insert Statement"], "metadata": {"chunk_id": "clients-wasm-data_ingestion-015", "document_id": "clients-wasm-data_ingestion", "position": 15, "token_count": 240, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Insert Statement"], "file_path": "clients/wasm/data_ingestion.md", "url": "/clients/wasm/data_ingestion", "title": "Data Ingestion", "category": null, "tags": [], "section_url": "/clients/wasm/data_ingestion#insert-statement"}}
