{"chunk_id": "data-csv-reading_faulty_csv_files-000", "document_id": "data-csv-reading_faulty_csv_files", "content": "CSV files can come in all shapes and forms, with some presenting many errors that make the process of cleanly reading them inherently difficult. To help users read these files, DuckDB supports detailed error messages, the ability to skip faulty lines, and the possibility of storing faulty lines in a temporary table to assist users with a data cleaning step.", "position": 0, "token_count": 71, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-000", "document_id": "data-csv-reading_faulty_csv_files", "position": 0, "token_count": 71, "has_code": false, "overlap_with_previous": false, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-001", "document_id": "data-csv-reading_faulty_csv_files", "content": "## Structural Errors\n\nDuckDB supports the detection and skipping of several different structural errors. In this section, we will go over each error with an example.\nFor the examples, consider the following table:\n\n```sql\nCREATE TABLE people (name VARCHAR, birth_date DATE);", "position": 1, "token_count": 61, "has_code": true, "section_hierarchy": ["Structural Errors"], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-001", "document_id": "data-csv-reading_faulty_csv_files", "position": 1, "token_count": 61, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Structural Errors"], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files#structural-errors"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-002", "document_id": "data-csv-reading_faulty_csv_files", "content": "```\n\nDuckDB detects the following error types:", "position": 2, "token_count": 14, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-002", "document_id": "data-csv-reading_faulty_csv_files", "position": 2, "token_count": 14, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-003", "document_id": "data-csv-reading_faulty_csv_files", "content": "* `CAST`: Casting errors occur when a column in the CSV file cannot be cast to the expected schema value. For example, the line `Pedro,The 90s` would cause an error since the string `The 90s` cannot be cast to a date.\n* `MISSING COLUMNS`: This error occurs if a line in the CSV file has fewer columns than expected. In our example, we expect two columns; therefore, a row with just one value, e.g., `Pedro`, would cause this error.\n* `TOO MANY COLUMNS`: This error occurs if a line in the CSV has more columns than expected. In our example, any line with more than two columns would cause this error, e.g., `Pedro,01-01-1992,pdet`.", "position": 3, "token_count": 169, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-003", "document_id": "data-csv-reading_faulty_csv_files", "position": 3, "token_count": 169, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-004", "document_id": "data-csv-reading_faulty_csv_files", "content": "* `UNQUOTED VALUE`: Quoted values in CSV lines must always be unquoted at the end; if a quoted value remains quoted throughout, it will cause an error. For example, assuming our scanner uses `quote='\"'`, the line `\"pedro\"holanda, 01-01-1992` would present an unquoted value error.\n* `LINE SIZE OVER MAXIMUM`: DuckDB has a parameter that sets the maximum line size a CSV file can have, which by default is set to 2,097,152 bytes. Assuming our scanner is set to `max_line_size = 25`, the line `Pedro Holanda, 01-01-1992` would produce an error, as it exceeds 25 bytes.\n* `INVALID ENCODING`: DuckDB supports UTF-8 strings, UTF-16 and Latin-1 encodings. Lines containing other characters will produce an error. For example, the line `pedro\\xff\\xff, 01-01-1992` would be problematic.", "position": 4, "token_count": 218, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-004", "document_id": "data-csv-reading_faulty_csv_files", "position": 4, "token_count": 218, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-005", "document_id": "data-csv-reading_faulty_csv_files", "content": "### Anatomy of a CSV Error\n\nBy default, when performing a CSV read, if any structural errors are encountered, the scanner will immediately stop the scanning process and throw the error to the user.\nThese errors are designed to provide as much information as possible to allow users to evaluate them directly in their CSV file.\n\nThis is an example for a full error message:\n\n```console\nConversion Error:\nCSV Error on Line: 5648\nOriginal Line: Pedro,The 90s\nError when converting column \"birth_date\". date field value out of range: \"The 90s\", expected format is (DD-MM-YYYY)\n\nColumn date is being converted as type DATE\nThis type was auto-detected from the CSV file.\nPossible solutions:\n* Override the type for this column manually by setting the type explicitly, e.g., types={'birth_date': 'VARCHAR'}\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\n* Use a COPY statement to automatically derive types from an existing table.", "position": 5, "token_count": 238, "has_code": true, "section_hierarchy": ["Anatomy of a CSV Error"], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-005", "document_id": "data-csv-reading_faulty_csv_files", "position": 5, "token_count": 238, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Anatomy of a CSV Error"], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files#anatomy-of-a-csv-error"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-006", "document_id": "data-csv-reading_faulty_csv_files", "content": "file= people.csv\n delimiter = , (Auto-Detected)\n quote = \" (Auto-Detected)\n escape = \" (Auto-Detected)\n new_line = \\r\\n (Auto-Detected)\n header = true (Auto-Detected)\n skip_rows = 0 (Auto-Detected)\n date_format = (DD-MM-YYYY) (Auto-Detected)\n timestamp_format = (Auto-Detected)\n null_padding=0\n sample_size=20480\n ignore_errors=false\n all_varchar=0", "position": 6, "token_count": 119, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-006", "document_id": "data-csv-reading_faulty_csv_files", "position": 6, "token_count": 119, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-007", "document_id": "data-csv-reading_faulty_csv_files", "content": "```\n\nThe first block provides us with information regarding where the error occurred, including the line number, the original CSV line, and which field was problematic:\n\n```console\nConversion Error:\nCSV Error on Line: 5648\nOriginal Line: Pedro,The 90s\nError when converting column \"birth_date\". date field value out of range: \"The 90s\", expected format is (DD-MM-YYYY)\n```\n\nThe second block provides us with potential solutions:\n\n```console\nColumn date is being converted as type DATE\nThis type was auto-detected from the CSV file.\nPossible solutions:\n* Override the type for this column manually by setting the type explicitly, e.g., types={'birth_date': 'VARCHAR'}\n* Set the sample size to a larger value to enable the auto-detection to scan more values, e.g., sample_size=-1\n* Use a COPY statement to automatically derive types from an existing table.", "position": 7, "token_count": 211, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-007", "document_id": "data-csv-reading_faulty_csv_files", "position": 7, "token_count": 211, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-008", "document_id": "data-csv-reading_faulty_csv_files", "content": "```\n\nSince the type of this field was auto-detected, it suggests defining the field as a `VARCHAR` or fully utilizing the dataset for type detection.\n\nFinally, the last block presents some of the options used in the scanner that can cause errors, indicating whether they were auto-detected or manually set by the user.", "position": 8, "token_count": 71, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-008", "document_id": "data-csv-reading_faulty_csv_files", "position": 8, "token_count": 71, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-009", "document_id": "data-csv-reading_faulty_csv_files", "content": "## Using the `ignore_errors` Option\n\nThere are cases where CSV files may have multiple structural errors, and users simply wish to skip these and read the correct data. Reading erroneous CSV files is possible by utilizing the `ignore_errors` option. With this option set, rows containing data that would otherwise cause the CSV parser to generate an error will be ignored. In our example, we will demonstrate a CAST error, but note that any of the errors described in our Structural Error section would cause the faulty line to be skipped.\n\nFor example, consider the following CSV file, [`faulty.csv`]({% link data/faulty.csv %}):\n\n```csv\nPedro,31\nOogie Boogie, three", "position": 9, "token_count": 161, "has_code": true, "section_hierarchy": ["Using the `ignore_errors` Option"], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-009", "document_id": "data-csv-reading_faulty_csv_files", "position": 9, "token_count": 161, "has_code": true, "overlap_with_previous": true, "section_hierarchy": ["Using the `ignore_errors` Option"], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files#using-the-ignoreerrors-option"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-010", "document_id": "data-csv-reading_faulty_csv_files", "content": "```\n\nIf you read the CSV file, specifying that the first column is a `VARCHAR` and the second column is an `INTEGER`, loading the file would fail, as the string `three` cannot be converted to an `INTEGER`.\n\nFor example, the following query will throw a casting error.\n\n```sql\nFROM read_csv('faulty.csv', columns = {'name': 'VARCHAR', 'age': 'INTEGER'});\n```\n\nHowever, with `ignore_errors` set, the second row of the file is skipped, outputting only the complete first row. For example:\n\n```sql\nFROM read_csv(\n 'faulty.csv',\n columns = {'name': 'VARCHAR', 'age': 'INTEGER'},\n ignore_errors = true\n);", "position": 10, "token_count": 188, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-010", "document_id": "data-csv-reading_faulty_csv_files", "position": 10, "token_count": 188, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-011", "document_id": "data-csv-reading_faulty_csv_files", "content": "```\n\nOutputs:\n\n| name | age |\n|-------|-----|\n| Pedro | 31 |\n\nOne should note that the CSV Parser is affected by the projection pushdown optimization. Hence, if we were to select only the name column, both rows would be considered valid, as the casting error on the age would never occur. For example:\n\n```sql\nSELECT name\nFROM read_csv('faulty.csv', columns = {'name': 'VARCHAR', 'age': 'INTEGER'});\n```\n\nOutputs:\n\n| name |\n|--------------|\n| Pedro |\n| Oogie Boogie |", "position": 11, "token_count": 158, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-011", "document_id": "data-csv-reading_faulty_csv_files", "position": 11, "token_count": 158, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-012", "document_id": "data-csv-reading_faulty_csv_files", "content": "## Retrieving Faulty CSV Lines\n\nBeing able to read faulty CSV files is important, but for many data cleaning operations, it is also necessary to know exactly which lines are corrupted and what errors the parser discovered on them. For scenarios like these, it is possible to use DuckDB's CSV Rejects Table feature.\nBy default, this feature creates two temporary tables.\n\n1. `reject_scans`: Stores information regarding the parameters of the CSV Scanner\n2. `reject_errors`: Stores information regarding each CSV faulty line and in which CSV Scanner they happened.\n\nNote that any of the errors described in our Structural Error section will be stored in the rejects tables. Also, if a line has multiple errors, multiple entries will be stored for the same line, one for each error.", "position": 12, "token_count": 167, "has_code": false, "section_hierarchy": ["Retrieving Faulty CSV Lines"], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-012", "document_id": "data-csv-reading_faulty_csv_files", "position": 12, "token_count": 167, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Retrieving Faulty CSV Lines"], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files#retrieving-faulty-csv-lines"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-013", "document_id": "data-csv-reading_faulty_csv_files", "content": "### Reject Scans\n\nThe CSV Reject Scans Table returns the following information:", "position": 13, "token_count": 18, "has_code": false, "section_hierarchy": ["Reject Scans"], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-013", "document_id": "data-csv-reading_faulty_csv_files", "position": 13, "token_count": 18, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Reject Scans"], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files#reject-scans"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-014", "document_id": "data-csv-reading_faulty_csv_files", "content": "| Column name | Description | Type |\n|:--|:-----|:-|\n| `scan_id` | The internal ID used in DuckDB to represent that scanner | `UBIGINT` |\n| `file_id` | A scanner might happen over multiple files, so the file_id represents a unique file in a scanner | `UBIGINT` |\n| `file_path` | The file path | `VARCHAR` |\n| `delimiter` | The delimiter used e.g., ; | `VARCHAR` |\n| `quote` | The quote used e.g., \" | `VARCHAR` |\n| `escape` | The quote used e.g., \" | `VARCHAR` |\n| `newline_delimiter` | The newline delimiter used e.g., \\r\\n | `VARCHAR` |", "position": 14, "token_count": 203, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-014", "document_id": "data-csv-reading_faulty_csv_files", "position": 14, "token_count": 203, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-015", "document_id": "data-csv-reading_faulty_csv_files", "content": "| `newline_delimiter` | The newline delimiter used e.g., \\r\\n | `VARCHAR` |\n| `skip_rows` | If any rows were skipped from the top of the file | `UINTEGER` |\n| `has_header` | If the file has a header | `BOOLEAN` |\n| `columns` | The schema of the file (i.e., all column names and types) | `VARCHAR` |\n| `date_format` | The format used for date types | `VARCHAR` |\n| `timestamp_format` | The format used for timestamp types| `VARCHAR` |\n| `user_arguments` | Any extra scanner parameters manually set by the user | `VARCHAR` |", "position": 15, "token_count": 176, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-015", "document_id": "data-csv-reading_faulty_csv_files", "position": 15, "token_count": 176, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-016", "document_id": "data-csv-reading_faulty_csv_files", "content": "### Reject Errors\n\nThe CSV Reject Errors Table returns the following information:", "position": 16, "token_count": 18, "has_code": false, "section_hierarchy": ["Reject Errors"], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-016", "document_id": "data-csv-reading_faulty_csv_files", "position": 16, "token_count": 18, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Reject Errors"], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files#reject-errors"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-017", "document_id": "data-csv-reading_faulty_csv_files", "content": "| Column name | Description | Type |\n|:--|:-----|:-|\n| `scan_id` | The internal ID used in DuckDB to represent that scanner, used to join with reject scans tables | `UBIGINT` |\n| `file_id` | The file_id represents a unique file in a scanner, used to join with reject scans tables | `UBIGINT` |\n| `line` | Line number, from the CSV File, where the error occurred. | `UBIGINT` |\n| `line_byte_position` | Byte Position of the start of the line, where the error occurred. | `UBIGINT` |\n| `byte_position` | Byte Position where the error occurred. | `UBIGINT` |\n| `column_idx` | If the error happens in a specific column, the index of the column. | `UBIGINT` |", "position": 17, "token_count": 204, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-017", "document_id": "data-csv-reading_faulty_csv_files", "position": 17, "token_count": 204, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-018", "document_id": "data-csv-reading_faulty_csv_files", "content": "| `column_idx` | If the error happens in a specific column, the index of the column. | `UBIGINT` |\n| `column_name` | If the error happens in a specific column, the name of the column. | `VARCHAR` |\n| `error_type` | The type of the error that happened. | `ENUM` |\n| `csv_line` | The original CSV line. | `VARCHAR` |\n| `error_message` | The error message produced by DuckDB. | `VARCHAR` |", "position": 18, "token_count": 126, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-018", "document_id": "data-csv-reading_faulty_csv_files", "position": 18, "token_count": 126, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-019", "document_id": "data-csv-reading_faulty_csv_files", "content": "## Parameters\n\nThe parameters listed below are used in the `read_csv` function to configure the CSV Rejects Table.\n\n| Name | Description | Type | Default |\n|:--|:-----|:-|:-|\n| `store_rejects` | If set to true, any errors in the file will be skipped and stored in the default rejects temporary tables.| `BOOLEAN` | False |\n| `rejects_scan` | Name of a temporary table where the information of the scan information of faulty CSV file are stored. | `VARCHAR` | reject_scans |\n| `rejects_table` | Name of a temporary table where the information of the faulty lines of a CSV file are stored. | `VARCHAR` | reject_errors |\n| `rejects_limit` | Upper limit on the number of faulty records from a CSV file that will be recorded in the rejects table. 0 is used when no limit should be applied. | `BIGINT` | 0 |", "position": 19, "token_count": 218, "has_code": false, "section_hierarchy": ["Parameters"], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-019", "document_id": "data-csv-reading_faulty_csv_files", "position": 19, "token_count": 218, "has_code": false, "overlap_with_previous": true, "section_hierarchy": ["Parameters"], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files#parameters"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-020", "document_id": "data-csv-reading_faulty_csv_files", "content": "To store the information of the faulty CSV lines in a rejects table, the user must simply set the `store_rejects` option to true. For example:\n\n```sql\nFROM read_csv(\n 'faulty.csv',\n columns = {'name': 'VARCHAR', 'age': 'INTEGER'},\n store_rejects = true\n);", "position": 20, "token_count": 81, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-020", "document_id": "data-csv-reading_faulty_csv_files", "position": 20, "token_count": 81, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-021", "document_id": "data-csv-reading_faulty_csv_files", "content": "```\n\nYou can then query both the `reject_scans` and `reject_errors` tables, to retrieve information about the rejected tuples. For example:\n\n```sql\nFROM reject_scans;", "position": 21, "token_count": 45, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-021", "document_id": "data-csv-reading_faulty_csv_files", "position": 21, "token_count": 45, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-022", "document_id": "data-csv-reading_faulty_csv_files", "content": "```\n\nOutputs:", "position": 22, "token_count": 7, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-022", "document_id": "data-csv-reading_faulty_csv_files", "position": 22, "token_count": 7, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-023", "document_id": "data-csv-reading_faulty_csv_files", "content": "| scan_id | file_id | file_path | delimiter | quote | escape | newline_delimiter | skip_rows | has_header | columns | date_format | timestamp_format | user_arguments |", "position": 23, "token_count": 54, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-023", "document_id": "data-csv-reading_faulty_csv_files", "position": 23, "token_count": 54, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-024", "document_id": "data-csv-reading_faulty_csv_files", "content": "|---------|---------|-----------------------------------|-----------|-------|--------|-------------------|-----------|-----------:|--------------------------------------|-------------|------------------|--------------------|", "position": 24, "token_count": 226, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-024", "document_id": "data-csv-reading_faulty_csv_files", "position": 24, "token_count": 226, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-025", "document_id": "data-csv-reading_faulty_csv_files", "content": "| 5 | 0 | faulty.csv | , | \" | \" | \\n | 0 | false | {'name': 'VARCHAR','age': 'INTEGER'} | | | store_rejects=true |", "position": 25, "token_count": 53, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-025", "document_id": "data-csv-reading_faulty_csv_files", "position": 25, "token_count": 53, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-026", "document_id": "data-csv-reading_faulty_csv_files", "content": "```sql\nFROM reject_errors;", "position": 26, "token_count": 11, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-026", "document_id": "data-csv-reading_faulty_csv_files", "position": 26, "token_count": 11, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-027", "document_id": "data-csv-reading_faulty_csv_files", "content": "```\n\nOutputs:", "position": 27, "token_count": 7, "has_code": true, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-027", "document_id": "data-csv-reading_faulty_csv_files", "position": 27, "token_count": 7, "has_code": true, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-028", "document_id": "data-csv-reading_faulty_csv_files", "content": "| scan_id | file_id | line | line_byte_position | byte_position | column_idx | column_name | error_type | csv_line | error_message |", "position": 28, "token_count": 45, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-028", "document_id": "data-csv-reading_faulty_csv_files", "position": 28, "token_count": 45, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-029", "document_id": "data-csv-reading_faulty_csv_files", "content": "|---------|---------|------|--------------------|---------------|------------|-------------|------------|---------------------|------------------------------------------------------------------------------------|", "position": 29, "token_count": 214, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-029", "document_id": "data-csv-reading_faulty_csv_files", "position": 29, "token_count": 214, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
{"chunk_id": "data-csv-reading_faulty_csv_files-030", "document_id": "data-csv-reading_faulty_csv_files", "content": "| 5 | 0 | 2 | 10 | 23 | 2 | age | CAST | Oogie Boogie, three | Error when converting column \"age\". Could not convert string \" three\" to 'INTEGER' |", "position": 30, "token_count": 46, "has_code": false, "section_hierarchy": [], "metadata": {"chunk_id": "data-csv-reading_faulty_csv_files-030", "document_id": "data-csv-reading_faulty_csv_files", "position": 30, "token_count": 46, "has_code": false, "overlap_with_previous": true, "section_hierarchy": [], "file_path": "data/csv/reading_faulty_csv_files.md", "url": "/data/csv/reading_faulty_csv_files", "title": "Reading Faulty CSV Files", "category": null, "tags": [], "section_url": "/data/csv/reading_faulty_csv_files"}}
